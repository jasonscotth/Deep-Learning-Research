{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f464635-7a33-4b32-83ba-648fa47170f5",
   "metadata": {},
   "source": [
    "# 2023 Research Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f464e2b7-d452-4535-8bac-ceb2ffa97481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from array import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec22d1c-60bf-4ef1-89b3-5201ba8876d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(871,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset & labels\n",
    "x_data = np.loadtxt('/home/jovyan/2023 Research/CC200_X_corr.csv', delimiter = ',')\n",
    "y_data = np.loadtxt('/home/jovyan/2023 Research/Y.csv', delimiter = ',')\n",
    "x_data_sampled_train = np.empty((696,x_data.shape[1]))\n",
    "x_data_sampled_val = np.empty((175,x_data.shape[1]))\n",
    "y_data_sampled_train = np.empty(696)\n",
    "y_data_sampled_val = np.empty(175)\n",
    "type(x_data)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e75a3cb-6095-4cc0-9b79-4c35b84cc872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#check for data normalization dynamic to the dimensions of the set\\nmax = 0.0\\nmin = 0.0\\ncount = 0\\ntemp = 0.0\\n\\nfor i in range(x_data.shape[0]):\\n    for j in range(x_data.shape[1]):\\n        temp = x_data[i][j]\\n        count += 1\\n        if temp > max:\\n            max = temp\\n        elif temp < min:\\n            min = temp\\n\\nprint(\"Checking for normalization of the data set...\")\\nprint(\"Max Value: {a:1.5f}\".format(a = max))\\nprint(\"Min Value: {a:1.5f}\".format(a = min))\\nprint(\"Elements Checked:\", count)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#check for data normalization dynamic to the dimensions of the set\n",
    "max = 0.0\n",
    "min = 0.0\n",
    "count = 0\n",
    "temp = 0.0\n",
    "\n",
    "for i in range(x_data.shape[0]):\n",
    "    for j in range(x_data.shape[1]):\n",
    "        temp = x_data[i][j]\n",
    "        count += 1\n",
    "        if temp > max:\n",
    "            max = temp\n",
    "        elif temp < min:\n",
    "            min = temp\n",
    "\n",
    "print(\"Checking for normalization of the data set...\")\n",
    "print(\"Max Value: {a:1.5f}\".format(a = max))\n",
    "print(\"Min Value: {a:1.5f}\".format(a = min))\n",
    "print(\"Elements Checked:\", count)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49088758-7109-4297-ad41-b7191e5c7d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Subgroups in Population...\n",
      "ASD Positive: 46.27% 403\n",
      "ASD Negative: 53.73% 468\n"
     ]
    }
   ],
   "source": [
    "#measure percent of positive vs negative samples in our set\n",
    "true = 0\n",
    "false = 0\n",
    "true_rate = 0.0\n",
    "false_rate = 0.0\n",
    "#pos samples 403\n",
    "#neg samples 468\n",
    "\n",
    "for x in range(x_data.shape[0]):\n",
    "    if y_data[x] == 1: \n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "    \n",
    "true_rate = true/(true+false) * 100\n",
    "false_rate = false/(true+false) * 100\n",
    "\n",
    "print(\"Distribution of Subgroups in Population...\")\n",
    "print(\"ASD Positive: {a:2.2f}%\".format(a = true_rate), true)\n",
    "print(\"ASD Negative: {a:2.2f}%\".format(a = false_rate), false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce2a2b63-17bb-40d3-a75a-a33cc7d59cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratifiedRandomSampling():\n",
    "    #split into categories\n",
    "    percentage = 0.0\n",
    "    pos_count = 0\n",
    "    total_count = 0\n",
    "    pos_range = 403\n",
    "    neg_range = 468\n",
    "    y = 0\n",
    "    z = 0\n",
    "    random_number = 0\n",
    "    \n",
    "    pos_strata = np.empty((403,x_data.shape[1]), dtype=float)\n",
    "    neg_strata = np.empty((468,x_data.shape[1]), dtype=float)\n",
    "    \n",
    "    for x in range(x_data.shape[0]):\n",
    "        if y_data[x] == 1:\n",
    "            pos_strata[y] = x_data[x]\n",
    "            y += 1\n",
    "        else:\n",
    "            neg_strata[z] = x_data[x]\n",
    "            z += 1\n",
    "            \n",
    "    #have selector so that starts with negative sample?\n",
    "    #right now is guaranteed to start with positive sample\n",
    "    #marker = random.randrange(start=0,stop=2)\n",
    "          \n",
    "    for x in range(696):\n",
    "        if percentage <= 0.46:\n",
    "            #add pos sample\n",
    "            #generate random number 0-402\n",
    "            rand_number = random.randrange(start=0,stop=pos_range)\n",
    "            #add to test_data -> guaranteed label 1\n",
    "            x_data_sampled_train[x] = pos_strata[random_number]\n",
    "            y_data_sampled_train[x] = 1\n",
    "            #remove record\n",
    "            np.delete(pos_strata, random_number, axis=1)\n",
    "            #calculate percentage\n",
    "            pos_range -= 1\n",
    "            pos_count += 1\n",
    "            total_count += 1\n",
    "            percentage = pos_count / total_count\n",
    "        else:\n",
    "            #add neg sample\n",
    "            #generate random number 0-467\n",
    "            rand_number = random.randrange(start=0,stop=neg_range)\n",
    "            #add to test_data -> guaranteed label 0\n",
    "            x_data_sampled_train[x] = neg_strata[random_number]\n",
    "            y_data_sampled_train[x] = 0\n",
    "            #remove record\n",
    "            np.delete(neg_strata, random_number, axis=1)\n",
    "            #calculate percentage\n",
    "            neg_range -= 1\n",
    "            total_count += 1\n",
    "            percentage = pos_count / total_count\n",
    "            \n",
    "    percentage = 0.0\n",
    "    pos_count = 0\n",
    "    total_count = 0\n",
    "            \n",
    "    for x in range(175):\n",
    "        if percentage <= 0.46:\n",
    "            #add pos sample\n",
    "            if pos_range == 0:\n",
    "                x_data_sampled_val[x] = pos_strata[0]\n",
    "                continue\n",
    "            #generate random number 0-402\n",
    "            rand_number = random.randrange(start=0,stop=pos_range)\n",
    "            #add to test_data -> guaranteed label 1\n",
    "            x_data_sampled_val[x] = pos_strata[random_number]\n",
    "            y_data_sampled_val[x] = 1\n",
    "            #remove record\n",
    "            np.delete(pos_strata, random_number, axis=1)\n",
    "            #calculate percentage\n",
    "            pos_range -= 1\n",
    "            pos_count += 1\n",
    "            total_count += 1\n",
    "            percentage = pos_count / total_count\n",
    "        else:\n",
    "            #add neg sample\n",
    "            if neg_range == 0:\n",
    "                x_data_sampled_val[x] = neg_strata[0]\n",
    "                continue\n",
    "            #generate random number 0-467\n",
    "            rand_number = random.randrange(start=0,stop=neg_range)\n",
    "            #add to test_data -> guaranteed label 0\n",
    "            x_data_sampled_val[x] = neg_strata[random_number]\n",
    "            y_data_sampled_val[x] = 0\n",
    "            #remove record\n",
    "            np.delete(neg_strata, random_number, axis=1)\n",
    "            #calculate percentage\n",
    "            neg_range -= 1\n",
    "            total_count += 1\n",
    "            percentage = pos_count / total_count\n",
    "        \n",
    "    print(x_data_sampled_train.shape,x_data_sampled_val.shape,y_data_sampled_train.shape,y_data_sampled_val.shape)\n",
    "    # when loop is done, remaining samples are copied to validation data\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "604d2a4b-174b-4f08-addc-f2d84ffc1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelConstructor():\n",
    "    y = x = keras.layers.Input(shape=x_data_sampled_train.shape[1:])\n",
    "    y = keras.layers.Flatten()(y)\n",
    "    y = keras.layers.Dropout(0.1)(y)\n",
    "    y = keras.layers.Dense(1000,activation=keras.activations.relu)(y)\n",
    "    #y = keras.layers.Dense(1000,activation=keras.activations.relu)(y)\n",
    "    y = keras.layers.Dense(len(np.unique(y_data_sampled_train)),\n",
    "                               activation=keras.activations.softmax)(y)\n",
    "    model = keras.Model(x,y)\n",
    "    #model.summary()\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 metrics=keras.metrics.SparseCategoricalAccuracy(),\n",
    "                 optimizer=keras.optimizers.Adam(learning_rate = 0.002))\n",
    "    keras.utils.plot_model(model,show_shapes=True,expand_nested=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc66ec65-18db-4b36-8783-d062ff38a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data structure to hold 10x results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac6636ab-e2e8-47ab-b24e-5277834fee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 20100) (175, 20100) (696,) (175,)\n"
     ]
    }
   ],
   "source": [
    "stratifiedRandomSampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ceede4a-7364-4947-8b16-a47edc4c9d06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_data_sampled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88f207dc-cd5b-494a-85a8-9493e1aff981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Training Count:  320\n",
      "Negative Training Count:  376\n",
      "Positive Validation Count:  83\n",
      "Negative Validation Count:  92\n"
     ]
    }
   ],
   "source": [
    "counter_train = 0\n",
    "counter_val = 0\n",
    "\n",
    "for x in range(y_data_sampled_train.shape[0]):\n",
    "    if y_data_sampled_train[x] == 1:\n",
    "        counter_train += 1\n",
    "\n",
    "for x in range(y_data_sampled_val.shape[0]):\n",
    "    if y_data_sampled_val[x] == 1:\n",
    "        counter_val += 1\n",
    "\n",
    "print(\"Positive Training Count: \", counter_train)\n",
    "print(\"Negative Training Count: \", 696-counter_train)\n",
    "print(\"Positive Validation Count: \", counter_val)\n",
    "print(\"Negative Validation Count: \", 175-counter_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cf1f317-947e-4ef8-8067-e8930f2937bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 0.0489 - sparse_categorical_accuracy: 0.9842 - val_loss: 5.5882 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 158ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 7.2567 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 92ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 7.8739 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 92ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Iteration: 1\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 1.3176 - sparse_categorical_accuracy: 0.8994 - val_loss: 5.4061 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 153ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.8939 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 93ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.0602 - val_sparse_categorical_accuracy: 0.9771 - 990ms/epoch - 90ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Iteration: 2\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 2.1597 - sparse_categorical_accuracy: 0.8118 - val_loss: 2.8689 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 151ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.4921 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 91ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.3454 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 92ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Iteration: 3\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 0.0719 - sparse_categorical_accuracy: 0.9368 - val_loss: 8.6343 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 153ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.1516 - val_sparse_categorical_accuracy: 0.9771 - 993ms/epoch - 90ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.0772 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 91ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Iteration: 4\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 0.0643 - sparse_categorical_accuracy: 0.9511 - val_loss: 6.0385 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 153ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 7.7518 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 94ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 8.3788 - val_sparse_categorical_accuracy: 0.9771 - 967ms/epoch - 88ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Iteration: 5\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 0.0509 - sparse_categorical_accuracy: 0.9799 - val_loss: 2.3635 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 151ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9748 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 94ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1949 - val_sparse_categorical_accuracy: 0.9771 - 969ms/epoch - 88ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Iteration: 6\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 1.7414 - sparse_categorical_accuracy: 0.8779 - val_loss: 2.0426 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 150ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3180 - val_sparse_categorical_accuracy: 0.9771 - 985ms/epoch - 90ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0433 - val_sparse_categorical_accuracy: 0.9771 - 960ms/epoch - 87ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Iteration: 7\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 0.4097 - sparse_categorical_accuracy: 0.8491 - val_loss: 3.5733 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 153ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.1211 - val_sparse_categorical_accuracy: 0.9771 - 993ms/epoch - 90ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.6795 - val_sparse_categorical_accuracy: 0.9771 - 996ms/epoch - 91ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Iteration: 8\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 2.4534 - sparse_categorical_accuracy: 0.8678 - val_loss: 2.3438 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 152ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3808 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 94ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0000 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 94ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Iteration: 9\n",
      "(696, 20100) (175, 20100) (696,) (175,)\n",
      "Epoch 1/3\n",
      "11/11 - 2s - loss: 0.0527 - sparse_categorical_accuracy: 0.9612 - val_loss: 3.1391 - val_sparse_categorical_accuracy: 0.9771 - 2s/epoch - 150ms/step\n",
      "Epoch 2/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0402 - val_sparse_categorical_accuracy: 0.9771 - 994ms/epoch - 90ms/step\n",
      "Epoch 3/3\n",
      "11/11 - 1s - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.3719 - val_sparse_categorical_accuracy: 0.9771 - 1s/epoch - 92ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Training Loss Average: 0.00000\n",
      "Training Accuracy Average: 100.00%\n",
      "Validation Loss Average: 4.37185\n",
      "Validation Accuracy Average: 97.71429%\n",
      "Label Accuracy Average: 2.29%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 175\n",
    "labels_accuracy = 0.0\n",
    "labels_accuracy_storage = np.empty(10,dtype=float)\n",
    "results = np.empty((10,4), dtype=float)\n",
    "\n",
    "#10 times cross validation\n",
    "for x in range(10):\n",
    "    print(\"Iteration:\", x)\n",
    "    stratifiedRandomSampling()\n",
    "    model = modelConstructor()\n",
    "    history = model.fit(x_data_sampled_train, y_data_sampled_train,\n",
    "                epochs=3,\n",
    "                verbose=2,\n",
    "                batch_size=64,\n",
    "                validation_data=(x_data_sampled_val,y_data_sampled_val))\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    accuracy = history.history['sparse_categorical_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_accuracy = history.history['val_sparse_categorical_accuracy']\n",
    "    \n",
    "    #get final results using last indexes\n",
    "    results[x][0] = loss[-1]\n",
    "    results[x][1] = accuracy[-1]\n",
    "    results[x][2] = val_loss[-1]\n",
    "    results[x][3] = val_accuracy[-1]\n",
    "    \n",
    "    output = model.predict(x_data_sampled_val[0:])\n",
    "    np.argmax(output,axis=1)\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for b in range(175):\n",
    "        temp1 = output[b][0]\n",
    "        temp2 = y_data_sampled_val[b]\n",
    "        if temp1 == temp2:\n",
    "            correct += 1\n",
    "    \n",
    "    labels_accuracy = correct/total\n",
    "    labels_accuracy_storage[x] = labels_accuracy\n",
    "    \n",
    "loss_avg = 0.0\n",
    "accuracy_avg = 0.0\n",
    "val_loss_avg = 0.0\n",
    "val_accuracy_avg = 0.0\n",
    "labels_accuracy_avg = 0.0\n",
    "\n",
    "for a in range(10):\n",
    "    loss_avg += results[x][0]\n",
    "for a in range(10):\n",
    "    accuracy_avg += results[x][1]\n",
    "for a in range(10):\n",
    "    val_loss_avg += results[x][2]\n",
    "for a in range(10):\n",
    "    val_accuracy_avg += results[x][3]\n",
    "    \n",
    "loss_avg = loss_avg / 10\n",
    "accuracy_avg = accuracy_avg / 10 * 100\n",
    "val_loss_avg = val_loss_avg / 10\n",
    "val_accuracy_avg = val_accuracy_avg / 10 * 100\n",
    "\n",
    "for a in range(10):\n",
    "    labels_accuracy_avg += labels_accuracy_storage[x]\n",
    "    \n",
    "labels_accuracy_avg = labels_accuracy_avg / 10 * 100\n",
    "\n",
    "print(\"Training Loss Average: {a:1.5f}\".format(a = loss_avg))\n",
    "print(\"Training Accuracy Average: {a:1.2f}%\".format(a = accuracy_avg))\n",
    "print(\"Validation Loss Average: {a:1.5f}\".format(a = val_loss_avg))\n",
    "print(\"Validation Accuracy Average: {a:1.5f}%\".format(a = val_accuracy_avg))\n",
    "print(\"Label Accuracy Average: {a:1.2f}%\".format(a = labels_accuracy_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7588527b-c545-4f68-9f09-3e4dbb241b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11],\n",
       "       [1.0000000e+00, 4.8417784e-11]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba400296-aac4-4664-82aa-45e7fcd22cbd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Hi love <3\n"
     ]
    }
   ],
   "source": [
    "for x in range(5):\n",
    "    print(x)\n",
    "print(\"Hi love <3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7717f0f8-41ac-47aa-86e6-b12ecc177624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boohoo\n"
     ]
    }
   ],
   "source": [
    "myNumber = 2\n",
    "secret = 3\n",
    "\n",
    "if myNumber == secret:\n",
    "    print(\"I found the secret number\")\n",
    "else:\n",
    "    print(\"boohoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cffa6-347b-48bf-93b8-23b1cf4abcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
