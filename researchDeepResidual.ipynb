{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f464635-7a33-4b32-83ba-648fa47170f5",
   "metadata": {},
   "source": [
    "## 2023 Research Deep Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f464e2b7-d452-4535-8bac-ceb2ffa97481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 17:31:26.627953: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import tools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from array import *\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec22d1c-60bf-4ef1-89b3-5201ba8876d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 77028) (696, 77028)\n"
     ]
    }
   ],
   "source": [
    "#import dataset & labels\n",
    "x_data = np.loadtxt(\"/home/jovyan/SummerResearch/Data/CC400_X_corr.csv\", delimiter = ',')\n",
    "y_data = np.loadtxt(\"/home/jovyan/SummerResearch/Data/Y.csv\", delimiter = ',')\n",
    "x_data_sampled_train = np.empty((696,x_data.shape[1]))\n",
    "x_data_sampled_val = np.empty((175,x_data.shape[1]))\n",
    "y_data_sampled_train = np.empty(696)\n",
    "y_data_sampled_val = np.empty(175)\n",
    "type(x_data)\n",
    "print(x_data.shape, x_data_sampled_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e75a3cb-6095-4cc0-9b79-4c35b84cc872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#check for data normalization dynamic to the dimensions of the set\\nmax = 0.0\\nmin = 0.0\\ncount = 0\\ntemp = 0.0\\n\\nfor i in range(x_data.shape[0]):\\n    for j in range(x_data.shape[1]):\\n        temp = x_data[i][j]\\n        count += 1\\n        if temp > max:\\n            max = temp\\n        elif temp < min:\\n            min = temp\\n\\nprint(\"Checking for normalization of the data set...\")\\nprint(\"Max Value: {a:1.5f}\".format(a = max))\\nprint(\"Min Value: {a:1.5f}\".format(a = min))\\nprint(\"Elements Checked:\", count)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#check for data normalization dynamic to the dimensions of the set\n",
    "max = 0.0\n",
    "min = 0.0\n",
    "count = 0\n",
    "temp = 0.0\n",
    "\n",
    "for i in range(x_data.shape[0]):\n",
    "    for j in range(x_data.shape[1]):\n",
    "        temp = x_data[i][j]\n",
    "        count += 1\n",
    "        if temp > max:\n",
    "            max = temp\n",
    "        elif temp < min:\n",
    "            min = temp\n",
    "\n",
    "print(\"Checking for normalization of the data set...\")\n",
    "print(\"Max Value: {a:1.5f}\".format(a = max))\n",
    "print(\"Min Value: {a:1.5f}\".format(a = min))\n",
    "print(\"Elements Checked:\", count)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49088758-7109-4297-ad41-b7191e5c7d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Subgroups in Population...\n",
      "ASD Positive: 46.27% 403\n",
      "ASD Negative: 53.73% 468\n"
     ]
    }
   ],
   "source": [
    "#measure percent of positive vs negative samples in our set\n",
    "true = 0\n",
    "false = 0\n",
    "true_rate = 0.0\n",
    "false_rate = 0.0\n",
    "#pos samples 403\n",
    "#neg samples 468\n",
    "\n",
    "for x in range(x_data.shape[0]):\n",
    "    if y_data[x] == 1: \n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "    \n",
    "true_rate = true/(true+false) * 100\n",
    "false_rate = false/(true+false) * 100\n",
    "\n",
    "print(\"Distribution of Subgroups in Population...\")\n",
    "print(\"ASD Positive: {a:2.2f}%\".format(a = true_rate), true)\n",
    "print(\"ASD Negative: {a:2.2f}%\".format(a = false_rate), false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2a2b63-17bb-40d3-a75a-a33cc7d59cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratifiedRandomSampling():\n",
    "    X = x_data\n",
    "    y = y_data\n",
    "    num_splits = 5\n",
    "    skf = StratifiedKFold(n_splits = num_splits, shuffle = True)\n",
    "    skf.get_n_splits(X, y)\n",
    "    skf = list(skf.split(X, y))\n",
    "    print(len(skf), len(skf[0]), len(skf[0][0]))\n",
    "    #for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        #print(f\"Fold {i}:\")\n",
    "        #print(f\"  Train: index={train_index}\")\n",
    "        #print(f\"  Test:  index={test_index}\")\n",
    "        \n",
    "    #train_index[696], test_index[175] = enumerate(skf.split(X, y))\n",
    "    \n",
    "    for x in range (696):\n",
    "        target = skf[0][0][x]\n",
    "        for y in range(x_data.shape[1]):\n",
    "            x_data_sampled_train[x][y] = x_data[target][y]\n",
    "        y_data_sampled_train[x] = y_data[target]\n",
    "    for x in range (175):\n",
    "        target = skf[0][1][x]\n",
    "        for y in range(x_data.shape[1]):\n",
    "            x_data_sampled_val[x][y] = x_data[target][y]\n",
    "        y_data_sampled_val[x] = y_data[target]\n",
    "        \n",
    "    #y_data_sampled_train\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604d2a4b-174b-4f08-addc-f2d84ffc1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelConstructor(n_hidden_units, n_hidden_layers):\n",
    "    y = x = keras.layers.Input(shape=x_data_sampled_train.shape[1:])\n",
    "    y = keras.layers.Flatten()(y)\n",
    "    y = keras.layers.Dense(n_hidden_units)(y)\n",
    "    for _ in range(n_hidden_layers):\n",
    "        y_resid = y\n",
    "        y = keras.layers.LayerNormalization()(y)\n",
    "        y = keras.layers.Dense(n_hidden_units,\n",
    "                               activation=keras.activations.relu)(y)\n",
    "        y = keras.layers.Add()([y,y_resid])\n",
    "    y = keras.layers.Dense(len(np.unique(y_data_sampled_train)),\n",
    "                               activation=keras.activations.softmax)(y)\n",
    "    model = keras.Model(x,y)\n",
    "    model.summary()\n",
    "    keras.utils.plot_model(model,show_shapes=True,expand_nested=True)\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=keras.metrics.SparseCategoricalAccuracy(),\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.002))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc66ec65-18db-4b36-8783-d062ff38a721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nepochs:         20\\nlearning rate:  0.001\\nhidden units:   2\\nhidden layers:  2\\nbatch size:     16\\nTraining Loss Average: 0.34587\\nTraining Accuracy Average: 91.09%\\nValidation Loss Average: 0.60430\\nValidation Accuracy Average: 67.42857%\\n\\nepochs:         20\\nlearning rate:  0.0015\\nhidden units:   2\\nhidden layers:  2\\nbatch size:     16\\nTraining Loss Average: 0.57873\\nTraining Accuracy Average: 76.15%\\nValidation Loss Average: 0.64881\\nValidation Accuracy Average: 60.57143%\\n\\nepochs:         20\\nlearning rate:  0.002\\nhidden units:   2\\nhidden layers:  2\\nbatch size:     16\\nTraining Loss Average: 0.33350\\nTraining Accuracy Average: 86.64%\\nValidation Loss Average: 0.63834\\nValidation Accuracy Average: 66.28571%\\n\\nepochs:         50\\nlearning rate:  0.001\\nhidden units:   2\\nhidden layers:  2\\nbatch size:     32\\nTraining Loss Average: 0.16432\\nTraining Accuracy Average: 96.84%\\nValidation Loss Average: 0.58706\\nValidation Accuracy Average: 73.71429%\\n\\nepochs:         50\\nlearning rate:  0.002\\nhidden units:   4\\nhidden layers:  4\\nbatch size:     32\\nTraining Loss Average: 0.13980\\nTraining Accuracy Average: 97.84%\\nValidation Loss Average: 0.53553\\nValidation Accuracy Average: 77.14286%\\n\\nepochs:         50\\nlearning rate:  0.002\\nhidden units:   4\\nhidden layers:  4\\nbatch size:     32\\nTraining Loss Average: 0.19247\\nTraining Accuracy Average: 93.39%\\nValidation Loss Average: 0.67157\\nValidation Accuracy Average: 66.28571%\\n\\nepochs:         50\\nlearning rate:  0.002\\nhidden units:   4\\nhidden layers:  4\\nbatch size:     32\\nTraining Loss Average: 0.37791\\nTraining Accuracy Average: 87.93%\\nValidation Loss Average: 0.65961\\nValidation Accuracy Average: 67.42857%\\n\\nepochs:         50\\nlearning rate:  0.002\\nhidden units:   4\\nhidden layers:  4\\nbatch size:     32\\nTraining Loss Average: 0.01198\\nTraining Accuracy Average: 100.00%\\nValidation Loss Average: 0.94252\\nValidation Accuracy Average: 63.42857%\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "epochs:         20\n",
    "learning rate:  0.001\n",
    "hidden units:   2\n",
    "hidden layers:  2\n",
    "batch size:     16\n",
    "Training Loss Average: 0.34587\n",
    "Training Accuracy Average: 91.09%\n",
    "Validation Loss Average: 0.60430\n",
    "Validation Accuracy Average: 67.42857%\n",
    "\n",
    "epochs:         20\n",
    "learning rate:  0.0015\n",
    "hidden units:   2\n",
    "hidden layers:  2\n",
    "batch size:     16\n",
    "Training Loss Average: 0.57873\n",
    "Training Accuracy Average: 76.15%\n",
    "Validation Loss Average: 0.64881\n",
    "Validation Accuracy Average: 60.57143%\n",
    "\n",
    "epochs:         20\n",
    "learning rate:  0.002\n",
    "hidden units:   2\n",
    "hidden layers:  2\n",
    "batch size:     16\n",
    "Training Loss Average: 0.33350\n",
    "Training Accuracy Average: 86.64%\n",
    "Validation Loss Average: 0.63834\n",
    "Validation Accuracy Average: 66.28571%\n",
    "\n",
    "epochs:         50\n",
    "learning rate:  0.001\n",
    "hidden units:   2\n",
    "hidden layers:  2\n",
    "batch size:     32\n",
    "Training Loss Average: 0.16432\n",
    "Training Accuracy Average: 96.84%\n",
    "Validation Loss Average: 0.58706\n",
    "Validation Accuracy Average: 73.71429%\n",
    "\n",
    "epochs:         50\n",
    "learning rate:  0.002\n",
    "hidden units:   4\n",
    "hidden layers:  4\n",
    "batch size:     32\n",
    "Training Loss Average: 0.13980\n",
    "Training Accuracy Average: 97.84%\n",
    "Validation Loss Average: 0.53553\n",
    "Validation Accuracy Average: 77.14286%\n",
    "\n",
    "epochs:         50\n",
    "learning rate:  0.002\n",
    "hidden units:   4\n",
    "hidden layers:  4\n",
    "batch size:     32\n",
    "Training Loss Average: 0.19247\n",
    "Training Accuracy Average: 93.39%\n",
    "Validation Loss Average: 0.67157\n",
    "Validation Accuracy Average: 66.28571%\n",
    "\n",
    "epochs:         50\n",
    "learning rate:  0.002\n",
    "hidden units:   4\n",
    "hidden layers:  4\n",
    "batch size:     32\n",
    "Training Loss Average: 0.37791\n",
    "Training Accuracy Average: 87.93%\n",
    "Validation Loss Average: 0.65961\n",
    "Validation Accuracy Average: 67.42857%\n",
    "\n",
    "epochs:         50\n",
    "learning rate:  0.002\n",
    "hidden units:   4\n",
    "hidden layers:  4\n",
    "batch size:     32\n",
    "Training Loss Average: 0.01198\n",
    "Training Accuracy Average: 100.00%\n",
    "Validation Loss Average: 0.94252\n",
    "Validation Accuracy Average: 63.42857%\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6636ab-e2e8-47ab-b24e-5277834fee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 696\n"
     ]
    }
   ],
   "source": [
    "skf = stratifiedRandomSampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ceede4a-7364-4947-8b16-a47edc4c9d06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_sampled_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f207dc-cd5b-494a-85a8-9493e1aff981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Training Count:  322\n",
      "Negative Training Count:  374\n",
      "Positive Validation Count:  81\n",
      "Negative Validation Count:  94\n"
     ]
    }
   ],
   "source": [
    "counter_train = 0\n",
    "counter_val = 0\n",
    "\n",
    "for x in range(y_data_sampled_train.shape[0]):\n",
    "    if y_data_sampled_train[x] == 1:\n",
    "        counter_train += 1\n",
    "\n",
    "for x in range(y_data_sampled_val.shape[0]):\n",
    "    if y_data_sampled_val[x] == 1:\n",
    "        counter_val += 1\n",
    "\n",
    "print(\"Positive Training Count: \", counter_train)\n",
    "print(\"Negative Training Count: \", 696-counter_train)\n",
    "print(\"Positive Validation Count: \", counter_val)\n",
    "print(\"Negative Validation Count: \", 175-counter_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf1f317-947e-4ef8-8067-e8930f2937bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "5 2 696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 17:37:29.818012: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-12 17:37:29.818064: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-12 17:37:29.818114: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-hwb2i): /proc/driver/nvidia/version does not exist\n",
      "2023-08-12 17:37:29.818478: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 77028)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 77028)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            308116      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 4)           8           ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            20          ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 4)            0           ['dense_1[0][0]',                \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 4)           8           ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4)            20          ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 4)            0           ['dense_2[0][0]',                \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 4)           8           ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4)            20          ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 4)            0           ['dense_3[0][0]',                \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 4)           8           ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4)            20          ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 4)            0           ['dense_4[0][0]',                \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            10          ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 308,238\n",
      "Trainable params: 308,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "22/22 - 2s - loss: 0.9696 - sparse_categorical_accuracy: 0.5388 - val_loss: 0.7217 - val_sparse_categorical_accuracy: 0.5371 - 2s/epoch - 103ms/step\n",
      "Epoch 2/100\n",
      "22/22 - 0s - loss: 0.7649 - sparse_categorical_accuracy: 0.5417 - val_loss: 0.7293 - val_sparse_categorical_accuracy: 0.5429 - 271ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "22/22 - 0s - loss: 0.7242 - sparse_categorical_accuracy: 0.5718 - val_loss: 0.8398 - val_sparse_categorical_accuracy: 0.4686 - 265ms/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "22/22 - 0s - loss: 0.6392 - sparse_categorical_accuracy: 0.6193 - val_loss: 0.8072 - val_sparse_categorical_accuracy: 0.4686 - 255ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "22/22 - 0s - loss: 0.6588 - sparse_categorical_accuracy: 0.6264 - val_loss: 0.6492 - val_sparse_categorical_accuracy: 0.6343 - 258ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "22/22 - 0s - loss: 0.7274 - sparse_categorical_accuracy: 0.5603 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.6343 - 240ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "22/22 - 0s - loss: 0.6282 - sparse_categorical_accuracy: 0.6825 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.5943 - 256ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "22/22 - 0s - loss: 0.5636 - sparse_categorical_accuracy: 0.7055 - val_loss: 0.7666 - val_sparse_categorical_accuracy: 0.5714 - 242ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "22/22 - 0s - loss: 0.5960 - sparse_categorical_accuracy: 0.6724 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000 - 246ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "22/22 - 0s - loss: 0.5086 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.7071 - val_sparse_categorical_accuracy: 0.5886 - 268ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "22/22 - 0s - loss: 0.5657 - sparse_categorical_accuracy: 0.7126 - val_loss: 0.6466 - val_sparse_categorical_accuracy: 0.5829 - 259ms/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "22/22 - 0s - loss: 0.5148 - sparse_categorical_accuracy: 0.7572 - val_loss: 0.6699 - val_sparse_categorical_accuracy: 0.5714 - 278ms/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "22/22 - 0s - loss: 0.4836 - sparse_categorical_accuracy: 0.7701 - val_loss: 0.8039 - val_sparse_categorical_accuracy: 0.5257 - 312ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "22/22 - 0s - loss: 0.4278 - sparse_categorical_accuracy: 0.8233 - val_loss: 0.6401 - val_sparse_categorical_accuracy: 0.6400 - 307ms/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "22/22 - 0s - loss: 0.4815 - sparse_categorical_accuracy: 0.7888 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.6571 - 298ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "22/22 - 0s - loss: 0.4708 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.6328 - val_sparse_categorical_accuracy: 0.6000 - 282ms/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "22/22 - 0s - loss: 0.4682 - sparse_categorical_accuracy: 0.7701 - val_loss: 0.6592 - val_sparse_categorical_accuracy: 0.6400 - 272ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "22/22 - 0s - loss: 0.4511 - sparse_categorical_accuracy: 0.8233 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.6000 - 247ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "22/22 - 0s - loss: 0.4572 - sparse_categorical_accuracy: 0.7802 - val_loss: 0.9061 - val_sparse_categorical_accuracy: 0.5771 - 500ms/epoch - 23ms/step\n",
      "Epoch 20/100\n",
      "22/22 - 0s - loss: 0.4170 - sparse_categorical_accuracy: 0.8520 - val_loss: 0.6363 - val_sparse_categorical_accuracy: 0.6229 - 256ms/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "22/22 - 0s - loss: 0.4385 - sparse_categorical_accuracy: 0.8333 - val_loss: 0.6639 - val_sparse_categorical_accuracy: 0.6457 - 248ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "22/22 - 0s - loss: 0.4412 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.7562 - val_sparse_categorical_accuracy: 0.5657 - 247ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "22/22 - 0s - loss: 0.3700 - sparse_categorical_accuracy: 0.8707 - val_loss: 0.6274 - val_sparse_categorical_accuracy: 0.6457 - 250ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "22/22 - 0s - loss: 0.4726 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.5886 - 269ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "22/22 - 0s - loss: 0.3048 - sparse_categorical_accuracy: 0.9124 - val_loss: 0.9960 - val_sparse_categorical_accuracy: 0.5314 - 300ms/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "22/22 - 0s - loss: 0.3646 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.8144 - val_sparse_categorical_accuracy: 0.5829 - 285ms/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "22/22 - 0s - loss: 0.3387 - sparse_categorical_accuracy: 0.8649 - val_loss: 0.6692 - val_sparse_categorical_accuracy: 0.5886 - 244ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "22/22 - 0s - loss: 0.4312 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.6316 - val_sparse_categorical_accuracy: 0.6457 - 262ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "22/22 - 0s - loss: 0.3539 - sparse_categorical_accuracy: 0.8578 - val_loss: 0.6665 - val_sparse_categorical_accuracy: 0.5886 - 273ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "22/22 - 0s - loss: 0.3127 - sparse_categorical_accuracy: 0.8865 - val_loss: 0.7671 - val_sparse_categorical_accuracy: 0.5829 - 272ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "22/22 - 0s - loss: 0.2962 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.7776 - val_sparse_categorical_accuracy: 0.6400 - 252ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "22/22 - 0s - loss: 0.2788 - sparse_categorical_accuracy: 0.9066 - val_loss: 0.7108 - val_sparse_categorical_accuracy: 0.6457 - 259ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "22/22 - 0s - loss: 0.3134 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.6437 - val_sparse_categorical_accuracy: 0.6457 - 268ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "22/22 - 0s - loss: 0.3350 - sparse_categorical_accuracy: 0.8678 - val_loss: 0.7689 - val_sparse_categorical_accuracy: 0.6343 - 259ms/epoch - 12ms/step\n",
      "Epoch 35/100\n",
      "22/22 - 0s - loss: 0.2948 - sparse_categorical_accuracy: 0.8908 - val_loss: 0.6346 - val_sparse_categorical_accuracy: 0.6571 - 257ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "22/22 - 0s - loss: 0.2685 - sparse_categorical_accuracy: 0.9210 - val_loss: 0.6443 - val_sparse_categorical_accuracy: 0.6514 - 264ms/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "22/22 - 0s - loss: 0.2612 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6114 - 263ms/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "22/22 - 0s - loss: 0.2736 - sparse_categorical_accuracy: 0.8966 - val_loss: 1.6420 - val_sparse_categorical_accuracy: 0.4686 - 259ms/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "22/22 - 0s - loss: 0.2132 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.6457 - 300ms/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "22/22 - 0s - loss: 0.2133 - sparse_categorical_accuracy: 0.9468 - val_loss: 0.7811 - val_sparse_categorical_accuracy: 0.5886 - 268ms/epoch - 12ms/step\n",
      "Epoch 41/100\n",
      "22/22 - 0s - loss: 0.1780 - sparse_categorical_accuracy: 0.9770 - val_loss: 0.6633 - val_sparse_categorical_accuracy: 0.6514 - 248ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "22/22 - 0s - loss: 0.2519 - sparse_categorical_accuracy: 0.9310 - val_loss: 0.9499 - val_sparse_categorical_accuracy: 0.5943 - 247ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "22/22 - 0s - loss: 0.1913 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.7811 - val_sparse_categorical_accuracy: 0.6343 - 238ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "22/22 - 0s - loss: 0.2566 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.8909 - val_sparse_categorical_accuracy: 0.5829 - 243ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "22/22 - 0s - loss: 0.2760 - sparse_categorical_accuracy: 0.9138 - val_loss: 1.1294 - val_sparse_categorical_accuracy: 0.5486 - 241ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "22/22 - 0s - loss: 0.2447 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.6641 - val_sparse_categorical_accuracy: 0.6571 - 244ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "22/22 - 0s - loss: 0.1982 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.6800 - 272ms/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "22/22 - 0s - loss: 0.2658 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.7133 - val_sparse_categorical_accuracy: 0.6686 - 244ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "22/22 - 0s - loss: 0.1869 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6457 - 252ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "22/22 - 0s - loss: 0.1503 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.6697 - val_sparse_categorical_accuracy: 0.6686 - 248ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "22/22 - 0s - loss: 0.1743 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.6971 - val_sparse_categorical_accuracy: 0.6629 - 253ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "22/22 - 0s - loss: 0.1660 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.6857 - 241ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "22/22 - 0s - loss: 0.1273 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6800 - 241ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "22/22 - 0s - loss: 0.1256 - sparse_categorical_accuracy: 0.9885 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6800 - 257ms/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "22/22 - 0s - loss: 0.1336 - sparse_categorical_accuracy: 0.9799 - val_loss: 1.4824 - val_sparse_categorical_accuracy: 0.5086 - 254ms/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "22/22 - 0s - loss: 0.2385 - sparse_categorical_accuracy: 0.9325 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.6514 - 264ms/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "22/22 - 0s - loss: 0.1128 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.7819 - val_sparse_categorical_accuracy: 0.6514 - 267ms/epoch - 12ms/step\n",
      "Epoch 58/100\n",
      "22/22 - 0s - loss: 0.1065 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.6571 - 246ms/epoch - 11ms/step\n",
      "Epoch 59/100\n",
      "22/22 - 0s - loss: 0.1006 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.8259 - val_sparse_categorical_accuracy: 0.6114 - 244ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "22/22 - 0s - loss: 0.1042 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.7281 - val_sparse_categorical_accuracy: 0.6857 - 249ms/epoch - 11ms/step\n",
      "Epoch 61/100\n",
      "22/22 - 0s - loss: 0.1328 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.7439 - val_sparse_categorical_accuracy: 0.6343 - 251ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "22/22 - 0s - loss: 0.1554 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.6963 - val_sparse_categorical_accuracy: 0.6629 - 254ms/epoch - 12ms/step\n",
      "Epoch 63/100\n",
      "22/22 - 0s - loss: 0.1020 - sparse_categorical_accuracy: 0.9871 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.6743 - 244ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "22/22 - 0s - loss: 0.0796 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.6743 - 248ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "22/22 - 0s - loss: 0.1583 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.7105 - val_sparse_categorical_accuracy: 0.6400 - 247ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "22/22 - 0s - loss: 0.1004 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.6972 - val_sparse_categorical_accuracy: 0.6743 - 251ms/epoch - 11ms/step\n",
      "Epoch 67/100\n",
      "22/22 - 0s - loss: 0.0817 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.6686 - 259ms/epoch - 12ms/step\n",
      "Epoch 68/100\n",
      "22/22 - 0s - loss: 0.0747 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.7280 - val_sparse_categorical_accuracy: 0.6686 - 247ms/epoch - 11ms/step\n",
      "Epoch 69/100\n",
      "22/22 - 0s - loss: 0.0791 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.6743 - 235ms/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "22/22 - 0s - loss: 0.1100 - sparse_categorical_accuracy: 0.9756 - val_loss: 1.1132 - val_sparse_categorical_accuracy: 0.5829 - 245ms/epoch - 11ms/step\n",
      "Epoch 71/100\n",
      "22/22 - 0s - loss: 0.2326 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.7164 - val_sparse_categorical_accuracy: 0.6800 - 233ms/epoch - 11ms/step\n",
      "Epoch 72/100\n",
      "22/22 - 0s - loss: 0.0640 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.6686 - 229ms/epoch - 10ms/step\n",
      "Epoch 73/100\n",
      "22/22 - 0s - loss: 0.0615 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7196 - val_sparse_categorical_accuracy: 0.6743 - 231ms/epoch - 11ms/step\n",
      "Epoch 74/100\n",
      "22/22 - 0s - loss: 0.0591 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7325 - val_sparse_categorical_accuracy: 0.6400 - 248ms/epoch - 11ms/step\n",
      "Epoch 75/100\n",
      "22/22 - 0s - loss: 0.0598 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7211 - val_sparse_categorical_accuracy: 0.6743 - 238ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "22/22 - 0s - loss: 0.0630 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7184 - val_sparse_categorical_accuracy: 0.6743 - 247ms/epoch - 11ms/step\n",
      "Epoch 77/100\n",
      "22/22 - 0s - loss: 0.0556 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7612 - val_sparse_categorical_accuracy: 0.6400 - 238ms/epoch - 11ms/step\n",
      "Epoch 78/100\n",
      "22/22 - 0s - loss: 0.0545 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7256 - val_sparse_categorical_accuracy: 0.6743 - 252ms/epoch - 11ms/step\n",
      "Epoch 79/100\n",
      "22/22 - 0s - loss: 0.0520 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7322 - val_sparse_categorical_accuracy: 0.6686 - 249ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "22/22 - 0s - loss: 0.0539 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7362 - val_sparse_categorical_accuracy: 0.6629 - 255ms/epoch - 12ms/step\n",
      "Epoch 81/100\n",
      "22/22 - 0s - loss: 0.0474 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7431 - val_sparse_categorical_accuracy: 0.6629 - 253ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "22/22 - 0s - loss: 0.0452 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7438 - val_sparse_categorical_accuracy: 0.6629 - 253ms/epoch - 11ms/step\n",
      "Epoch 83/100\n",
      "22/22 - 0s - loss: 0.0462 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7745 - val_sparse_categorical_accuracy: 0.6457 - 252ms/epoch - 11ms/step\n",
      "Epoch 84/100\n",
      "22/22 - 0s - loss: 0.0452 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7788 - val_sparse_categorical_accuracy: 0.6457 - 241ms/epoch - 11ms/step\n",
      "Epoch 85/100\n",
      "22/22 - 0s - loss: 0.0399 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8120 - val_sparse_categorical_accuracy: 0.6457 - 247ms/epoch - 11ms/step\n",
      "Epoch 86/100\n",
      "22/22 - 0s - loss: 0.0348 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7920 - val_sparse_categorical_accuracy: 0.6514 - 274ms/epoch - 12ms/step\n",
      "Epoch 87/100\n",
      "22/22 - 0s - loss: 0.1218 - sparse_categorical_accuracy: 0.9440 - val_loss: 0.7673 - val_sparse_categorical_accuracy: 0.6343 - 250ms/epoch - 11ms/step\n",
      "Epoch 88/100\n",
      "22/22 - 0s - loss: 0.0450 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7501 - val_sparse_categorical_accuracy: 0.6514 - 242ms/epoch - 11ms/step\n",
      "Epoch 89/100\n",
      "22/22 - 0s - loss: 0.0431 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7519 - val_sparse_categorical_accuracy: 0.6571 - 272ms/epoch - 12ms/step\n",
      "Epoch 90/100\n",
      "22/22 - 0s - loss: 0.0351 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7866 - val_sparse_categorical_accuracy: 0.6514 - 244ms/epoch - 11ms/step\n",
      "Epoch 91/100\n",
      "22/22 - 0s - loss: 0.0312 - sparse_categorical_accuracy: 0.9971 - val_loss: 1.6400 - val_sparse_categorical_accuracy: 0.5829 - 237ms/epoch - 11ms/step\n",
      "Epoch 92/100\n",
      "22/22 - 0s - loss: 0.2026 - sparse_categorical_accuracy: 0.9425 - val_loss: 0.7538 - val_sparse_categorical_accuracy: 0.6629 - 235ms/epoch - 11ms/step\n",
      "Epoch 93/100\n",
      "22/22 - 0s - loss: 0.0427 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7666 - val_sparse_categorical_accuracy: 0.6571 - 241ms/epoch - 11ms/step\n",
      "Epoch 94/100\n",
      "22/22 - 0s - loss: 0.0399 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7643 - val_sparse_categorical_accuracy: 0.6743 - 240ms/epoch - 11ms/step\n",
      "Epoch 95/100\n",
      "22/22 - 0s - loss: 0.0370 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7624 - val_sparse_categorical_accuracy: 0.6629 - 236ms/epoch - 11ms/step\n",
      "Epoch 96/100\n",
      "22/22 - 0s - loss: 0.0348 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7663 - val_sparse_categorical_accuracy: 0.6629 - 234ms/epoch - 11ms/step\n",
      "Epoch 97/100\n",
      "22/22 - 0s - loss: 0.0336 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7708 - val_sparse_categorical_accuracy: 0.6629 - 277ms/epoch - 13ms/step\n",
      "Epoch 98/100\n",
      "22/22 - 0s - loss: 0.0313 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7904 - val_sparse_categorical_accuracy: 0.6457 - 231ms/epoch - 11ms/step\n",
      "Epoch 99/100\n",
      "22/22 - 0s - loss: 0.0297 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8094 - val_sparse_categorical_accuracy: 0.6457 - 230ms/epoch - 10ms/step\n",
      "Epoch 100/100\n",
      "22/22 - 0s - loss: 0.0269 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7997 - val_sparse_categorical_accuracy: 0.6571 - 226ms/epoch - 10ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Iteration: 1\n",
      "5 2 696\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 77028)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 77028)        0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4)            308116      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 4)           8           ['dense_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4)            20          ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 4)            0           ['dense_7[0][0]',                \n",
      "                                                                  'dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 4)           8           ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 4)            20          ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 4)            0           ['dense_8[0][0]',                \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 4)           8           ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 4)            20          ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 4)            0           ['dense_9[0][0]',                \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 4)           8           ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 4)            20          ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 4)            0           ['dense_10[0][0]',               \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 2)            10          ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 308,238\n",
      "Trainable params: 308,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "22/22 - 2s - loss: 1.3447 - sparse_categorical_accuracy: 0.4899 - val_loss: 0.7407 - val_sparse_categorical_accuracy: 0.4686 - 2s/epoch - 92ms/step\n",
      "Epoch 2/100\n",
      "22/22 - 0s - loss: 0.9037 - sparse_categorical_accuracy: 0.5287 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.5086 - 250ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "22/22 - 0s - loss: 0.7226 - sparse_categorical_accuracy: 0.5575 - val_loss: 1.5206 - val_sparse_categorical_accuracy: 0.5371 - 279ms/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "22/22 - 0s - loss: 0.6414 - sparse_categorical_accuracy: 0.6609 - val_loss: 0.7472 - val_sparse_categorical_accuracy: 0.5429 - 255ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "22/22 - 0s - loss: 0.6788 - sparse_categorical_accuracy: 0.6178 - val_loss: 0.6221 - val_sparse_categorical_accuracy: 0.7086 - 245ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "22/22 - 0s - loss: 0.5740 - sparse_categorical_accuracy: 0.6810 - val_loss: 0.7473 - val_sparse_categorical_accuracy: 0.5429 - 241ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "22/22 - 0s - loss: 0.6622 - sparse_categorical_accuracy: 0.6351 - val_loss: 0.7501 - val_sparse_categorical_accuracy: 0.5314 - 260ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "22/22 - 0s - loss: 0.5827 - sparse_categorical_accuracy: 0.6767 - val_loss: 0.7392 - val_sparse_categorical_accuracy: 0.5257 - 235ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "22/22 - 0s - loss: 0.5366 - sparse_categorical_accuracy: 0.7572 - val_loss: 0.8157 - val_sparse_categorical_accuracy: 0.5200 - 252ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "22/22 - 0s - loss: 0.5386 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.7168 - val_sparse_categorical_accuracy: 0.5543 - 242ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "22/22 - 0s - loss: 0.6346 - sparse_categorical_accuracy: 0.6767 - val_loss: 0.6185 - val_sparse_categorical_accuracy: 0.6457 - 247ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "22/22 - 0s - loss: 0.5397 - sparse_categorical_accuracy: 0.7342 - val_loss: 0.6106 - val_sparse_categorical_accuracy: 0.6571 - 249ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "22/22 - 0s - loss: 0.6796 - sparse_categorical_accuracy: 0.6149 - val_loss: 0.7080 - val_sparse_categorical_accuracy: 0.5543 - 231ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "22/22 - 0s - loss: 0.5075 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.7724 - val_sparse_categorical_accuracy: 0.5486 - 241ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "22/22 - 0s - loss: 0.5411 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.5861 - val_sparse_categorical_accuracy: 0.7143 - 230ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "22/22 - 0s - loss: 0.4911 - sparse_categorical_accuracy: 0.8017 - val_loss: 0.7335 - val_sparse_categorical_accuracy: 0.5714 - 230ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "22/22 - 0s - loss: 0.4130 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.6686 - 241ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "22/22 - 0s - loss: 0.4822 - sparse_categorical_accuracy: 0.7730 - val_loss: 0.5873 - val_sparse_categorical_accuracy: 0.7200 - 263ms/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "22/22 - 0s - loss: 0.4069 - sparse_categorical_accuracy: 0.8376 - val_loss: 0.5729 - val_sparse_categorical_accuracy: 0.7257 - 235ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "22/22 - 0s - loss: 0.4422 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.5669 - val_sparse_categorical_accuracy: 0.7143 - 252ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "22/22 - 0s - loss: 0.4100 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.5811 - val_sparse_categorical_accuracy: 0.6686 - 238ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "22/22 - 0s - loss: 0.4290 - sparse_categorical_accuracy: 0.8477 - val_loss: 0.5676 - val_sparse_categorical_accuracy: 0.7257 - 240ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "22/22 - 0s - loss: 0.3998 - sparse_categorical_accuracy: 0.8261 - val_loss: 1.1284 - val_sparse_categorical_accuracy: 0.5371 - 261ms/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "22/22 - 0s - loss: 0.4955 - sparse_categorical_accuracy: 0.7672 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.6914 - 244ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "22/22 - 0s - loss: 0.3763 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.6582 - val_sparse_categorical_accuracy: 0.6457 - 255ms/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "22/22 - 0s - loss: 0.4200 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.5681 - val_sparse_categorical_accuracy: 0.7086 - 282ms/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "22/22 - 0s - loss: 0.3485 - sparse_categorical_accuracy: 0.8649 - val_loss: 0.6149 - val_sparse_categorical_accuracy: 0.6686 - 243ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "22/22 - 0s - loss: 0.3562 - sparse_categorical_accuracy: 0.8477 - val_loss: 1.0064 - val_sparse_categorical_accuracy: 0.5429 - 242ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "22/22 - 0s - loss: 0.3915 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.5750 - val_sparse_categorical_accuracy: 0.6914 - 248ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "22/22 - 0s - loss: 0.2784 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.5486 - val_sparse_categorical_accuracy: 0.7371 - 238ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "22/22 - 0s - loss: 0.2653 - sparse_categorical_accuracy: 0.9109 - val_loss: 0.6406 - val_sparse_categorical_accuracy: 0.6857 - 248ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "22/22 - 0s - loss: 0.5463 - sparse_categorical_accuracy: 0.7572 - val_loss: 0.9598 - val_sparse_categorical_accuracy: 0.5429 - 251ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "22/22 - 0s - loss: 0.3272 - sparse_categorical_accuracy: 0.8448 - val_loss: 0.7284 - val_sparse_categorical_accuracy: 0.6286 - 238ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "22/22 - 0s - loss: 0.3490 - sparse_categorical_accuracy: 0.8563 - val_loss: 0.5527 - val_sparse_categorical_accuracy: 0.7371 - 240ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "22/22 - 0s - loss: 0.3007 - sparse_categorical_accuracy: 0.8836 - val_loss: 0.7533 - val_sparse_categorical_accuracy: 0.6514 - 237ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "22/22 - 0s - loss: 0.3807 - sparse_categorical_accuracy: 0.8305 - val_loss: 0.5628 - val_sparse_categorical_accuracy: 0.7143 - 250ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "22/22 - 0s - loss: 0.1899 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.5681 - val_sparse_categorical_accuracy: 0.7257 - 237ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "22/22 - 0s - loss: 0.2798 - sparse_categorical_accuracy: 0.9181 - val_loss: 0.5754 - val_sparse_categorical_accuracy: 0.7029 - 239ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "22/22 - 0s - loss: 0.3817 - sparse_categorical_accuracy: 0.8261 - val_loss: 0.5601 - val_sparse_categorical_accuracy: 0.7371 - 237ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "22/22 - 0s - loss: 0.3430 - sparse_categorical_accuracy: 0.8434 - val_loss: 1.1612 - val_sparse_categorical_accuracy: 0.5257 - 260ms/epoch - 12ms/step\n",
      "Epoch 41/100\n",
      "22/22 - 0s - loss: 0.2836 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.6151 - val_sparse_categorical_accuracy: 0.6857 - 290ms/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "22/22 - 0s - loss: 0.2545 - sparse_categorical_accuracy: 0.9124 - val_loss: 0.5622 - val_sparse_categorical_accuracy: 0.7029 - 256ms/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "22/22 - 0s - loss: 0.1697 - sparse_categorical_accuracy: 0.9511 - val_loss: 2.5543 - val_sparse_categorical_accuracy: 0.5371 - 236ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "22/22 - 0s - loss: 0.3918 - sparse_categorical_accuracy: 0.8549 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.7029 - 254ms/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "22/22 - 0s - loss: 0.1193 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.8032 - val_sparse_categorical_accuracy: 0.6686 - 249ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "22/22 - 0s - loss: 0.3674 - sparse_categorical_accuracy: 0.8779 - val_loss: 0.5909 - val_sparse_categorical_accuracy: 0.6971 - 268ms/epoch - 12ms/step\n",
      "Epoch 47/100\n",
      "22/22 - 0s - loss: 0.1934 - sparse_categorical_accuracy: 0.9397 - val_loss: 0.6577 - val_sparse_categorical_accuracy: 0.6971 - 263ms/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "22/22 - 0s - loss: 0.1825 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.5759 - val_sparse_categorical_accuracy: 0.7371 - 275ms/epoch - 12ms/step\n",
      "Epoch 49/100\n",
      "22/22 - 0s - loss: 0.2300 - sparse_categorical_accuracy: 0.9325 - val_loss: 0.5824 - val_sparse_categorical_accuracy: 0.6971 - 321ms/epoch - 15ms/step\n",
      "Epoch 50/100\n",
      "22/22 - 0s - loss: 0.3630 - sparse_categorical_accuracy: 0.8520 - val_loss: 0.5628 - val_sparse_categorical_accuracy: 0.7486 - 320ms/epoch - 15ms/step\n",
      "Epoch 51/100\n",
      "22/22 - 0s - loss: 0.1065 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.6163 - val_sparse_categorical_accuracy: 0.6857 - 272ms/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "22/22 - 0s - loss: 0.2896 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.6743 - 251ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "22/22 - 0s - loss: 0.1420 - sparse_categorical_accuracy: 0.9770 - val_loss: 0.7233 - val_sparse_categorical_accuracy: 0.6686 - 237ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "22/22 - 0s - loss: 0.0821 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.6002 - val_sparse_categorical_accuracy: 0.7371 - 240ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "22/22 - 0s - loss: 0.0568 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.7257 - 240ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "22/22 - 0s - loss: 0.1467 - sparse_categorical_accuracy: 0.9612 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.7086 - 227ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "22/22 - 0s - loss: 0.0532 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.7510 - val_sparse_categorical_accuracy: 0.7029 - 225ms/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "22/22 - 0s - loss: 0.2759 - sparse_categorical_accuracy: 0.9109 - val_loss: 0.6555 - val_sparse_categorical_accuracy: 0.7086 - 228ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "22/22 - 0s - loss: 0.0649 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.7143 - 224ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "22/22 - 0s - loss: 0.1858 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.6914 - 239ms/epoch - 11ms/step\n",
      "Epoch 61/100\n",
      "22/22 - 0s - loss: 0.0447 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.7029 - 239ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "22/22 - 0s - loss: 0.0336 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7539 - val_sparse_categorical_accuracy: 0.7314 - 265ms/epoch - 12ms/step\n",
      "Epoch 63/100\n",
      "22/22 - 0s - loss: 0.2278 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.6800 - 246ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "22/22 - 0s - loss: 0.2429 - sparse_categorical_accuracy: 0.9339 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.7029 - 237ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "22/22 - 0s - loss: 0.0550 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.7298 - val_sparse_categorical_accuracy: 0.6914 - 247ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "22/22 - 0s - loss: 0.0310 - sparse_categorical_accuracy: 0.9971 - val_loss: 1.4531 - val_sparse_categorical_accuracy: 0.5657 - 238ms/epoch - 11ms/step\n",
      "Epoch 67/100\n",
      "22/22 - 0s - loss: 0.2958 - sparse_categorical_accuracy: 0.9095 - val_loss: 0.7203 - val_sparse_categorical_accuracy: 0.7086 - 240ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "22/22 - 0s - loss: 0.0340 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7480 - val_sparse_categorical_accuracy: 0.7029 - 238ms/epoch - 11ms/step\n",
      "Epoch 69/100\n",
      "22/22 - 0s - loss: 0.0248 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8233 - val_sparse_categorical_accuracy: 0.6857 - 237ms/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "22/22 - 0s - loss: 0.0225 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8080 - val_sparse_categorical_accuracy: 0.7029 - 277ms/epoch - 13ms/step\n",
      "Epoch 71/100\n",
      "22/22 - 0s - loss: 0.0212 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8111 - val_sparse_categorical_accuracy: 0.6971 - 241ms/epoch - 11ms/step\n",
      "Epoch 72/100\n",
      "22/22 - 0s - loss: 0.0210 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8152 - val_sparse_categorical_accuracy: 0.7029 - 246ms/epoch - 11ms/step\n",
      "Epoch 73/100\n",
      "22/22 - 0s - loss: 0.0195 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8199 - val_sparse_categorical_accuracy: 0.7029 - 245ms/epoch - 11ms/step\n",
      "Epoch 74/100\n",
      "22/22 - 0s - loss: 0.0189 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8319 - val_sparse_categorical_accuracy: 0.7086 - 233ms/epoch - 11ms/step\n",
      "Epoch 75/100\n",
      "22/22 - 0s - loss: 0.0182 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8234 - val_sparse_categorical_accuracy: 0.7029 - 233ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "22/22 - 0s - loss: 0.0176 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8447 - val_sparse_categorical_accuracy: 0.7029 - 239ms/epoch - 11ms/step\n",
      "Epoch 77/100\n",
      "22/22 - 0s - loss: 0.0171 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8477 - val_sparse_categorical_accuracy: 0.7143 - 236ms/epoch - 11ms/step\n",
      "Epoch 78/100\n",
      "22/22 - 0s - loss: 0.0166 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8454 - val_sparse_categorical_accuracy: 0.6914 - 237ms/epoch - 11ms/step\n",
      "Epoch 79/100\n",
      "22/22 - 0s - loss: 0.0162 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8555 - val_sparse_categorical_accuracy: 0.7086 - 233ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "22/22 - 0s - loss: 0.0157 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8529 - val_sparse_categorical_accuracy: 0.7029 - 270ms/epoch - 12ms/step\n",
      "Epoch 81/100\n",
      "22/22 - 0s - loss: 0.0153 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8557 - val_sparse_categorical_accuracy: 0.7086 - 232ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "22/22 - 0s - loss: 0.0149 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8667 - val_sparse_categorical_accuracy: 0.7029 - 255ms/epoch - 12ms/step\n",
      "Epoch 83/100\n",
      "22/22 - 0s - loss: 0.0145 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8664 - val_sparse_categorical_accuracy: 0.6971 - 258ms/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "22/22 - 0s - loss: 0.0142 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8617 - val_sparse_categorical_accuracy: 0.6971 - 257ms/epoch - 12ms/step\n",
      "Epoch 85/100\n",
      "22/22 - 0s - loss: 0.0138 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8773 - val_sparse_categorical_accuracy: 0.6971 - 252ms/epoch - 11ms/step\n",
      "Epoch 86/100\n",
      "22/22 - 0s - loss: 0.0136 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8749 - val_sparse_categorical_accuracy: 0.6971 - 240ms/epoch - 11ms/step\n",
      "Epoch 87/100\n",
      "22/22 - 0s - loss: 0.0132 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8715 - val_sparse_categorical_accuracy: 0.7029 - 248ms/epoch - 11ms/step\n",
      "Epoch 88/100\n",
      "22/22 - 0s - loss: 0.0129 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8771 - val_sparse_categorical_accuracy: 0.6971 - 239ms/epoch - 11ms/step\n",
      "Epoch 89/100\n",
      "22/22 - 0s - loss: 0.0127 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8747 - val_sparse_categorical_accuracy: 0.6971 - 225ms/epoch - 10ms/step\n",
      "Epoch 90/100\n",
      "22/22 - 0s - loss: 0.0125 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8827 - val_sparse_categorical_accuracy: 0.6971 - 234ms/epoch - 11ms/step\n",
      "Epoch 91/100\n",
      "22/22 - 0s - loss: 0.0122 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8984 - val_sparse_categorical_accuracy: 0.7029 - 249ms/epoch - 11ms/step\n",
      "Epoch 92/100\n",
      "22/22 - 0s - loss: 0.0120 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8970 - val_sparse_categorical_accuracy: 0.7029 - 254ms/epoch - 12ms/step\n",
      "Epoch 93/100\n",
      "22/22 - 0s - loss: 0.0117 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9002 - val_sparse_categorical_accuracy: 0.6971 - 236ms/epoch - 11ms/step\n",
      "Epoch 94/100\n",
      "22/22 - 0s - loss: 0.0115 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9052 - val_sparse_categorical_accuracy: 0.7029 - 247ms/epoch - 11ms/step\n",
      "Epoch 95/100\n",
      "22/22 - 0s - loss: 0.0113 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9062 - val_sparse_categorical_accuracy: 0.7029 - 244ms/epoch - 11ms/step\n",
      "Epoch 96/100\n",
      "22/22 - 0s - loss: 0.0111 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8987 - val_sparse_categorical_accuracy: 0.6914 - 237ms/epoch - 11ms/step\n",
      "Epoch 97/100\n",
      "22/22 - 0s - loss: 0.0109 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9134 - val_sparse_categorical_accuracy: 0.7029 - 257ms/epoch - 12ms/step\n",
      "Epoch 98/100\n",
      "22/22 - 0s - loss: 0.0107 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9010 - val_sparse_categorical_accuracy: 0.6857 - 237ms/epoch - 11ms/step\n",
      "Epoch 99/100\n",
      "22/22 - 0s - loss: 0.0104 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9157 - val_sparse_categorical_accuracy: 0.6914 - 253ms/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "22/22 - 0s - loss: 0.0103 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9070 - val_sparse_categorical_accuracy: 0.6857 - 266ms/epoch - 12ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Iteration: 2\n",
      "5 2 696\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 77028)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 77028)        0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 4)            308116      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 4)           8           ['dense_12[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 4)            20          ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 4)            0           ['dense_13[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 4)           8           ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 4)            20          ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 4)            0           ['dense_14[0][0]',               \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 4)           8           ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 4)            20          ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 4)            0           ['dense_15[0][0]',               \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 4)           8           ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 4)            20          ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 4)            0           ['dense_16[0][0]',               \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 2)            10          ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 308,238\n",
      "Trainable params: 308,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "22/22 - 2s - loss: 5.6666 - sparse_categorical_accuracy: 0.5503 - val_loss: 2.7130 - val_sparse_categorical_accuracy: 0.4686 - 2s/epoch - 93ms/step\n",
      "Epoch 2/100\n",
      "22/22 - 0s - loss: 4.4400 - sparse_categorical_accuracy: 0.5302 - val_loss: 7.8529 - val_sparse_categorical_accuracy: 0.5371 - 268ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "22/22 - 0s - loss: 3.9520 - sparse_categorical_accuracy: 0.5273 - val_loss: 1.1127 - val_sparse_categorical_accuracy: 0.5771 - 256ms/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "22/22 - 0s - loss: 3.3869 - sparse_categorical_accuracy: 0.5259 - val_loss: 1.2067 - val_sparse_categorical_accuracy: 0.5943 - 293ms/epoch - 13ms/step\n",
      "Epoch 5/100\n",
      "22/22 - 0s - loss: 2.6414 - sparse_categorical_accuracy: 0.5503 - val_loss: 4.8629 - val_sparse_categorical_accuracy: 0.5371 - 252ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "22/22 - 0s - loss: 2.2563 - sparse_categorical_accuracy: 0.5905 - val_loss: 2.6669 - val_sparse_categorical_accuracy: 0.5429 - 254ms/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "22/22 - 0s - loss: 2.2234 - sparse_categorical_accuracy: 0.5647 - val_loss: 3.2884 - val_sparse_categorical_accuracy: 0.5314 - 263ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "22/22 - 0s - loss: 1.0607 - sparse_categorical_accuracy: 0.6839 - val_loss: 1.4611 - val_sparse_categorical_accuracy: 0.5771 - 246ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "22/22 - 0s - loss: 1.4592 - sparse_categorical_accuracy: 0.6293 - val_loss: 5.5493 - val_sparse_categorical_accuracy: 0.5371 - 255ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "22/22 - 0s - loss: 1.3144 - sparse_categorical_accuracy: 0.6480 - val_loss: 1.8439 - val_sparse_categorical_accuracy: 0.5086 - 250ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "22/22 - 0s - loss: 0.7280 - sparse_categorical_accuracy: 0.7342 - val_loss: 1.0353 - val_sparse_categorical_accuracy: 0.5714 - 262ms/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "22/22 - 0s - loss: 0.9300 - sparse_categorical_accuracy: 0.6624 - val_loss: 1.1622 - val_sparse_categorical_accuracy: 0.6000 - 241ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "22/22 - 0s - loss: 0.7490 - sparse_categorical_accuracy: 0.7313 - val_loss: 1.9279 - val_sparse_categorical_accuracy: 0.5429 - 246ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "22/22 - 0s - loss: 0.9922 - sparse_categorical_accuracy: 0.6767 - val_loss: 0.9653 - val_sparse_categorical_accuracy: 0.5771 - 248ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "22/22 - 0s - loss: 0.5723 - sparse_categorical_accuracy: 0.7787 - val_loss: 1.3024 - val_sparse_categorical_accuracy: 0.5886 - 224ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "22/22 - 0s - loss: 0.4942 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6800 - 229ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "22/22 - 0s - loss: 0.3533 - sparse_categorical_accuracy: 0.8707 - val_loss: 1.1168 - val_sparse_categorical_accuracy: 0.6000 - 229ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "22/22 - 0s - loss: 0.5419 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.8807 - val_sparse_categorical_accuracy: 0.6057 - 246ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "22/22 - 0s - loss: 0.3837 - sparse_categorical_accuracy: 0.8563 - val_loss: 1.1170 - val_sparse_categorical_accuracy: 0.6114 - 247ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "22/22 - 0s - loss: 0.7402 - sparse_categorical_accuracy: 0.7428 - val_loss: 1.3430 - val_sparse_categorical_accuracy: 0.5143 - 238ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "22/22 - 0s - loss: 0.4313 - sparse_categorical_accuracy: 0.8161 - val_loss: 0.9451 - val_sparse_categorical_accuracy: 0.5886 - 234ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "22/22 - 0s - loss: 0.5079 - sparse_categorical_accuracy: 0.7744 - val_loss: 0.8074 - val_sparse_categorical_accuracy: 0.6114 - 241ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "22/22 - 0s - loss: 0.3057 - sparse_categorical_accuracy: 0.8736 - val_loss: 0.7497 - val_sparse_categorical_accuracy: 0.6229 - 256ms/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "22/22 - 0s - loss: 0.2311 - sparse_categorical_accuracy: 0.9224 - val_loss: 0.7171 - val_sparse_categorical_accuracy: 0.6000 - 260ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "22/22 - 0s - loss: 0.2842 - sparse_categorical_accuracy: 0.8937 - val_loss: 0.7134 - val_sparse_categorical_accuracy: 0.5943 - 314ms/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "22/22 - 0s - loss: 0.2101 - sparse_categorical_accuracy: 0.9339 - val_loss: 1.6786 - val_sparse_categorical_accuracy: 0.4857 - 312ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "22/22 - 0s - loss: 0.2704 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.6477 - val_sparse_categorical_accuracy: 0.6971 - 288ms/epoch - 13ms/step\n",
      "Epoch 28/100\n",
      "22/22 - 0s - loss: 0.2521 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.6171 - 259ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "22/22 - 0s - loss: 0.1765 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6400 - 269ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "22/22 - 0s - loss: 0.2027 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.6171 - 244ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "22/22 - 0s - loss: 0.1664 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6857 - 241ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "22/22 - 0s - loss: 0.5777 - sparse_categorical_accuracy: 0.7601 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.6286 - 238ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "22/22 - 0s - loss: 0.1521 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.8182 - val_sparse_categorical_accuracy: 0.6171 - 264ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "22/22 - 0s - loss: 0.2910 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.6607 - val_sparse_categorical_accuracy: 0.6857 - 241ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "22/22 - 0s - loss: 0.1684 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.6743 - 252ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "22/22 - 0s - loss: 0.1226 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.9837 - val_sparse_categorical_accuracy: 0.5771 - 265ms/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "22/22 - 0s - loss: 0.2994 - sparse_categorical_accuracy: 0.9066 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.6343 - 241ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "22/22 - 0s - loss: 0.1142 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.6229 - 240ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "22/22 - 0s - loss: 0.1102 - sparse_categorical_accuracy: 0.9885 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.6400 - 249ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "22/22 - 0s - loss: 0.3131 - sparse_categorical_accuracy: 0.8664 - val_loss: 0.8202 - val_sparse_categorical_accuracy: 0.6229 - 276ms/epoch - 13ms/step\n",
      "Epoch 41/100\n",
      "22/22 - 0s - loss: 0.1058 - sparse_categorical_accuracy: 0.9885 - val_loss: 0.6948 - val_sparse_categorical_accuracy: 0.6571 - 258ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "22/22 - 0s - loss: 0.1015 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.6971 - 275ms/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "22/22 - 0s - loss: 0.1014 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.7415 - val_sparse_categorical_accuracy: 0.6686 - 250ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "22/22 - 0s - loss: 0.1440 - sparse_categorical_accuracy: 0.9598 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.6686 - 268ms/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "22/22 - 0s - loss: 0.0956 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.8949 - val_sparse_categorical_accuracy: 0.6171 - 242ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "22/22 - 0s - loss: 0.0900 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.7535 - val_sparse_categorical_accuracy: 0.6171 - 252ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "22/22 - 0s - loss: 0.0958 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.7367 - val_sparse_categorical_accuracy: 0.6171 - 256ms/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "22/22 - 0s - loss: 0.0858 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.7521 - val_sparse_categorical_accuracy: 0.6571 - 301ms/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "22/22 - 0s - loss: 0.1481 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.8323 - val_sparse_categorical_accuracy: 0.6229 - 226ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "22/22 - 0s - loss: 0.1162 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.7894 - val_sparse_categorical_accuracy: 0.6171 - 239ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "22/22 - 0s - loss: 0.0820 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7416 - val_sparse_categorical_accuracy: 0.6171 - 242ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "22/22 - 0s - loss: 0.0750 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8283 - val_sparse_categorical_accuracy: 0.6171 - 236ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "22/22 - 0s - loss: 0.1093 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.6914 - 227ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "22/22 - 0s - loss: 0.0672 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7349 - val_sparse_categorical_accuracy: 0.6286 - 250ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "22/22 - 0s - loss: 0.0745 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.7891 - val_sparse_categorical_accuracy: 0.6229 - 238ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "22/22 - 0s - loss: 0.0777 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.7182 - val_sparse_categorical_accuracy: 0.6571 - 234ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "22/22 - 0s - loss: 0.0682 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.7811 - val_sparse_categorical_accuracy: 0.6171 - 237ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "22/22 - 0s - loss: 0.0704 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7770 - val_sparse_categorical_accuracy: 0.6229 - 252ms/epoch - 11ms/step\n",
      "Epoch 59/100\n",
      "22/22 - 0s - loss: 0.0815 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.6914 - 222ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "22/22 - 0s - loss: 0.0590 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7260 - val_sparse_categorical_accuracy: 0.6514 - 233ms/epoch - 11ms/step\n",
      "Epoch 61/100\n",
      "22/22 - 0s - loss: 0.0612 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7129 - val_sparse_categorical_accuracy: 0.6800 - 239ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "22/22 - 0s - loss: 0.0565 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8053 - val_sparse_categorical_accuracy: 0.6229 - 246ms/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "22/22 - 0s - loss: 0.0574 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7487 - val_sparse_categorical_accuracy: 0.6743 - 248ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "22/22 - 0s - loss: 0.0608 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.7074 - val_sparse_categorical_accuracy: 0.6857 - 232ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "22/22 - 0s - loss: 0.0532 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7048 - val_sparse_categorical_accuracy: 0.6800 - 241ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "22/22 - 0s - loss: 0.0530 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7356 - val_sparse_categorical_accuracy: 0.6629 - 225ms/epoch - 10ms/step\n",
      "Epoch 67/100\n",
      "22/22 - 0s - loss: 0.0527 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.6857 - 232ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "22/22 - 0s - loss: 0.0509 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8412 - val_sparse_categorical_accuracy: 0.6229 - 252ms/epoch - 11ms/step\n",
      "Epoch 69/100\n",
      "22/22 - 0s - loss: 0.0489 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7158 - val_sparse_categorical_accuracy: 0.6857 - 252ms/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "22/22 - 0s - loss: 0.0475 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7753 - val_sparse_categorical_accuracy: 0.6229 - 241ms/epoch - 11ms/step\n",
      "Epoch 71/100\n",
      "22/22 - 0s - loss: 0.0462 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7228 - val_sparse_categorical_accuracy: 0.6800 - 247ms/epoch - 11ms/step\n",
      "Epoch 72/100\n",
      "22/22 - 0s - loss: 0.0451 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7148 - val_sparse_categorical_accuracy: 0.6971 - 244ms/epoch - 11ms/step\n",
      "Epoch 73/100\n",
      "22/22 - 0s - loss: 0.0430 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7188 - val_sparse_categorical_accuracy: 0.6914 - 249ms/epoch - 11ms/step\n",
      "Epoch 74/100\n",
      "22/22 - 0s - loss: 0.0421 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7187 - val_sparse_categorical_accuracy: 0.6971 - 302ms/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "22/22 - 0s - loss: 0.0423 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7533 - val_sparse_categorical_accuracy: 0.6571 - 239ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "22/22 - 0s - loss: 0.0427 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7614 - val_sparse_categorical_accuracy: 0.6514 - 267ms/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "22/22 - 0s - loss: 0.0391 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7934 - val_sparse_categorical_accuracy: 0.6229 - 231ms/epoch - 11ms/step\n",
      "Epoch 78/100\n",
      "22/22 - 0s - loss: 0.0390 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7659 - val_sparse_categorical_accuracy: 0.6514 - 243ms/epoch - 11ms/step\n",
      "Epoch 79/100\n",
      "22/22 - 0s - loss: 0.0385 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7348 - val_sparse_categorical_accuracy: 0.6857 - 236ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "22/22 - 0s - loss: 0.0383 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7346 - val_sparse_categorical_accuracy: 0.6857 - 225ms/epoch - 10ms/step\n",
      "Epoch 81/100\n",
      "22/22 - 0s - loss: 0.0371 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8026 - val_sparse_categorical_accuracy: 0.6229 - 246ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "22/22 - 0s - loss: 0.0378 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7280 - val_sparse_categorical_accuracy: 0.6971 - 249ms/epoch - 11ms/step\n",
      "Epoch 83/100\n",
      "22/22 - 0s - loss: 0.0367 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7330 - val_sparse_categorical_accuracy: 0.6914 - 223ms/epoch - 10ms/step\n",
      "Epoch 84/100\n",
      "22/22 - 0s - loss: 0.0355 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7406 - val_sparse_categorical_accuracy: 0.6857 - 234ms/epoch - 11ms/step\n",
      "Epoch 85/100\n",
      "22/22 - 0s - loss: 0.0348 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7427 - val_sparse_categorical_accuracy: 0.6914 - 241ms/epoch - 11ms/step\n",
      "Epoch 86/100\n",
      "22/22 - 0s - loss: 0.0343 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7487 - val_sparse_categorical_accuracy: 0.6743 - 234ms/epoch - 11ms/step\n",
      "Epoch 87/100\n",
      "22/22 - 0s - loss: 0.0333 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7382 - val_sparse_categorical_accuracy: 0.6914 - 241ms/epoch - 11ms/step\n",
      "Epoch 88/100\n",
      "22/22 - 0s - loss: 0.0321 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7675 - val_sparse_categorical_accuracy: 0.6571 - 238ms/epoch - 11ms/step\n",
      "Epoch 89/100\n",
      "22/22 - 0s - loss: 0.0320 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7629 - val_sparse_categorical_accuracy: 0.6686 - 251ms/epoch - 11ms/step\n",
      "Epoch 90/100\n",
      "22/22 - 0s - loss: 0.0311 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7392 - val_sparse_categorical_accuracy: 0.6914 - 229ms/epoch - 10ms/step\n",
      "Epoch 91/100\n",
      "22/22 - 0s - loss: 0.0306 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7480 - val_sparse_categorical_accuracy: 0.6914 - 245ms/epoch - 11ms/step\n",
      "Epoch 92/100\n",
      "22/22 - 0s - loss: 0.0309 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7814 - val_sparse_categorical_accuracy: 0.6571 - 238ms/epoch - 11ms/step\n",
      "Epoch 93/100\n",
      "22/22 - 0s - loss: 0.0296 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7642 - val_sparse_categorical_accuracy: 0.6686 - 236ms/epoch - 11ms/step\n",
      "Epoch 94/100\n",
      "22/22 - 0s - loss: 0.0293 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7708 - val_sparse_categorical_accuracy: 0.6629 - 245ms/epoch - 11ms/step\n",
      "Epoch 95/100\n",
      "22/22 - 0s - loss: 0.0289 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7625 - val_sparse_categorical_accuracy: 0.6743 - 226ms/epoch - 10ms/step\n",
      "Epoch 96/100\n",
      "22/22 - 0s - loss: 0.0282 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7615 - val_sparse_categorical_accuracy: 0.6743 - 235ms/epoch - 11ms/step\n",
      "Epoch 97/100\n",
      "22/22 - 0s - loss: 0.0273 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7574 - val_sparse_categorical_accuracy: 0.6914 - 244ms/epoch - 11ms/step\n",
      "Epoch 98/100\n",
      "22/22 - 0s - loss: 0.0276 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7765 - val_sparse_categorical_accuracy: 0.6571 - 231ms/epoch - 11ms/step\n",
      "Epoch 99/100\n",
      "22/22 - 0s - loss: 0.0266 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7938 - val_sparse_categorical_accuracy: 0.6571 - 263ms/epoch - 12ms/step\n",
      "Epoch 100/100\n",
      "22/22 - 0s - loss: 0.0260 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7627 - val_sparse_categorical_accuracy: 0.6914 - 230ms/epoch - 10ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Iteration: 3\n",
      "5 2 696\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 77028)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 77028)        0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 4)            308116      ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 4)           8           ['dense_18[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 4)            20          ['layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 4)            0           ['dense_19[0][0]',               \n",
      "                                                                  'dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 4)           8           ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 4)            20          ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 4)            0           ['dense_20[0][0]',               \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 4)           8           ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 4)            20          ['layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 4)            0           ['dense_21[0][0]',               \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 4)           8           ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 4)            20          ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 4)            0           ['dense_22[0][0]',               \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 2)            10          ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 308,238\n",
      "Trainable params: 308,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "22/22 - 2s - loss: 1.0499 - sparse_categorical_accuracy: 0.4957 - val_loss: 0.7309 - val_sparse_categorical_accuracy: 0.4971 - 2s/epoch - 91ms/step\n",
      "Epoch 2/100\n",
      "22/22 - 0s - loss: 0.7518 - sparse_categorical_accuracy: 0.5388 - val_loss: 0.7301 - val_sparse_categorical_accuracy: 0.5371 - 282ms/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "22/22 - 0s - loss: 0.7005 - sparse_categorical_accuracy: 0.5776 - val_loss: 0.7356 - val_sparse_categorical_accuracy: 0.5200 - 259ms/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "22/22 - 0s - loss: 0.6465 - sparse_categorical_accuracy: 0.6293 - val_loss: 0.8162 - val_sparse_categorical_accuracy: 0.5371 - 267ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "22/22 - 0s - loss: 0.6453 - sparse_categorical_accuracy: 0.6595 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.6171 - 254ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "22/22 - 0s - loss: 0.6030 - sparse_categorical_accuracy: 0.6825 - val_loss: 0.7395 - val_sparse_categorical_accuracy: 0.5657 - 263ms/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "22/22 - 0s - loss: 0.5917 - sparse_categorical_accuracy: 0.7098 - val_loss: 0.6349 - val_sparse_categorical_accuracy: 0.6343 - 243ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "22/22 - 0s - loss: 0.6079 - sparse_categorical_accuracy: 0.6897 - val_loss: 0.6566 - val_sparse_categorical_accuracy: 0.6171 - 258ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "22/22 - 0s - loss: 0.5512 - sparse_categorical_accuracy: 0.7083 - val_loss: 0.8179 - val_sparse_categorical_accuracy: 0.5086 - 284ms/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "22/22 - 0s - loss: 0.5889 - sparse_categorical_accuracy: 0.6825 - val_loss: 0.6611 - val_sparse_categorical_accuracy: 0.5657 - 253ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "22/22 - 0s - loss: 0.5322 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.8752 - val_sparse_categorical_accuracy: 0.4971 - 259ms/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "22/22 - 0s - loss: 0.5343 - sparse_categorical_accuracy: 0.7256 - val_loss: 0.8197 - val_sparse_categorical_accuracy: 0.5543 - 249ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "22/22 - 0s - loss: 0.4851 - sparse_categorical_accuracy: 0.7759 - val_loss: 0.6386 - val_sparse_categorical_accuracy: 0.6229 - 253ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "22/22 - 0s - loss: 0.4702 - sparse_categorical_accuracy: 0.7917 - val_loss: 1.1690 - val_sparse_categorical_accuracy: 0.4914 - 242ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "22/22 - 0s - loss: 0.4617 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.7706 - val_sparse_categorical_accuracy: 0.5771 - 236ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "22/22 - 0s - loss: 0.4961 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.6142 - val_sparse_categorical_accuracy: 0.6743 - 243ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "22/22 - 0s - loss: 0.3862 - sparse_categorical_accuracy: 0.8276 - val_loss: 1.3620 - val_sparse_categorical_accuracy: 0.5371 - 229ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "22/22 - 0s - loss: 0.5115 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.6068 - val_sparse_categorical_accuracy: 0.6914 - 241ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "22/22 - 0s - loss: 0.3847 - sparse_categorical_accuracy: 0.8348 - val_loss: 0.7069 - val_sparse_categorical_accuracy: 0.5714 - 240ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "22/22 - 0s - loss: 0.3877 - sparse_categorical_accuracy: 0.8276 - val_loss: 0.6147 - val_sparse_categorical_accuracy: 0.6914 - 248ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "22/22 - 0s - loss: 0.4304 - sparse_categorical_accuracy: 0.8046 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.6343 - 265ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "22/22 - 0s - loss: 0.3860 - sparse_categorical_accuracy: 0.8290 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.5886 - 283ms/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "22/22 - 0s - loss: 0.4226 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.6024 - val_sparse_categorical_accuracy: 0.6686 - 252ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "22/22 - 0s - loss: 0.3861 - sparse_categorical_accuracy: 0.8477 - val_loss: 0.7296 - val_sparse_categorical_accuracy: 0.6114 - 236ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "22/22 - 0s - loss: 0.4046 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.6202 - val_sparse_categorical_accuracy: 0.6743 - 228ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "22/22 - 0s - loss: 0.3163 - sparse_categorical_accuracy: 0.8649 - val_loss: 0.9035 - val_sparse_categorical_accuracy: 0.5543 - 233ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "22/22 - 0s - loss: 0.3821 - sparse_categorical_accuracy: 0.8779 - val_loss: 0.9668 - val_sparse_categorical_accuracy: 0.5314 - 259ms/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "22/22 - 0s - loss: 0.3316 - sparse_categorical_accuracy: 0.8980 - val_loss: 0.9685 - val_sparse_categorical_accuracy: 0.5371 - 236ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "22/22 - 0s - loss: 0.3122 - sparse_categorical_accuracy: 0.8693 - val_loss: 0.6435 - val_sparse_categorical_accuracy: 0.6857 - 256ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "22/22 - 0s - loss: 0.3213 - sparse_categorical_accuracy: 0.8836 - val_loss: 1.1569 - val_sparse_categorical_accuracy: 0.5143 - 241ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "22/22 - 0s - loss: 0.3014 - sparse_categorical_accuracy: 0.8865 - val_loss: 0.8445 - val_sparse_categorical_accuracy: 0.5829 - 265ms/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "22/22 - 0s - loss: 0.2967 - sparse_categorical_accuracy: 0.8793 - val_loss: 1.1691 - val_sparse_categorical_accuracy: 0.5714 - 258ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "22/22 - 0s - loss: 0.3497 - sparse_categorical_accuracy: 0.8405 - val_loss: 0.7668 - val_sparse_categorical_accuracy: 0.6343 - 240ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "22/22 - 0s - loss: 0.2100 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.6772 - val_sparse_categorical_accuracy: 0.6629 - 259ms/epoch - 12ms/step\n",
      "Epoch 35/100\n",
      "22/22 - 0s - loss: 0.3714 - sparse_categorical_accuracy: 0.8534 - val_loss: 1.6083 - val_sparse_categorical_accuracy: 0.4800 - 238ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "22/22 - 0s - loss: 0.2263 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.6629 - 242ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "22/22 - 0s - loss: 0.2401 - sparse_categorical_accuracy: 0.9282 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.6971 - 239ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "22/22 - 0s - loss: 0.4124 - sparse_categorical_accuracy: 0.8305 - val_loss: 0.6087 - val_sparse_categorical_accuracy: 0.7086 - 237ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "22/22 - 0s - loss: 0.2058 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.6939 - val_sparse_categorical_accuracy: 0.6514 - 239ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "22/22 - 0s - loss: 0.2350 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.8412 - val_sparse_categorical_accuracy: 0.6629 - 231ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "22/22 - 0s - loss: 0.2753 - sparse_categorical_accuracy: 0.8851 - val_loss: 0.6154 - val_sparse_categorical_accuracy: 0.6743 - 267ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "22/22 - 0s - loss: 0.2095 - sparse_categorical_accuracy: 0.9598 - val_loss: 0.5968 - val_sparse_categorical_accuracy: 0.7029 - 241ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "22/22 - 0s - loss: 0.2463 - sparse_categorical_accuracy: 0.9239 - val_loss: 0.5934 - val_sparse_categorical_accuracy: 0.7257 - 239ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "22/22 - 0s - loss: 0.1759 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.6590 - val_sparse_categorical_accuracy: 0.6629 - 236ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "22/22 - 0s - loss: 0.2185 - sparse_categorical_accuracy: 0.9397 - val_loss: 0.7867 - val_sparse_categorical_accuracy: 0.6114 - 242ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "22/22 - 0s - loss: 0.1734 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.6270 - val_sparse_categorical_accuracy: 0.7086 - 240ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "22/22 - 0s - loss: 0.1830 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.6150 - val_sparse_categorical_accuracy: 0.6971 - 219ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "22/22 - 0s - loss: 0.1745 - sparse_categorical_accuracy: 0.9655 - val_loss: 0.8393 - val_sparse_categorical_accuracy: 0.6000 - 241ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "22/22 - 0s - loss: 0.1410 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.6098 - val_sparse_categorical_accuracy: 0.6971 - 276ms/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "22/22 - 0s - loss: 0.2008 - sparse_categorical_accuracy: 0.9325 - val_loss: 1.1507 - val_sparse_categorical_accuracy: 0.5771 - 264ms/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "22/22 - 0s - loss: 0.1619 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.6203 - val_sparse_categorical_accuracy: 0.6800 - 247ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "22/22 - 0s - loss: 0.1512 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.6686 - 243ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "22/22 - 0s - loss: 0.1371 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.6232 - val_sparse_categorical_accuracy: 0.7029 - 245ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "22/22 - 0s - loss: 0.2022 - sparse_categorical_accuracy: 0.9239 - val_loss: 0.8024 - val_sparse_categorical_accuracy: 0.6400 - 240ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "22/22 - 0s - loss: 0.1125 - sparse_categorical_accuracy: 0.9871 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6914 - 236ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "22/22 - 0s - loss: 0.1160 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.7438 - val_sparse_categorical_accuracy: 0.6514 - 238ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "22/22 - 0s - loss: 0.2502 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.6305 - val_sparse_categorical_accuracy: 0.6914 - 243ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "22/22 - 0s - loss: 0.1633 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.6267 - val_sparse_categorical_accuracy: 0.7200 - 260ms/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "22/22 - 0s - loss: 0.0935 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.6514 - 257ms/epoch - 12ms/step\n",
      "Epoch 60/100\n",
      "22/22 - 0s - loss: 0.0883 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.6634 - val_sparse_categorical_accuracy: 0.6800 - 230ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "22/22 - 0s - loss: 0.0830 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.6429 - val_sparse_categorical_accuracy: 0.6914 - 234ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "22/22 - 0s - loss: 0.2027 - sparse_categorical_accuracy: 0.9282 - val_loss: 0.6249 - val_sparse_categorical_accuracy: 0.7200 - 253ms/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "22/22 - 0s - loss: 0.0776 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.6857 - 238ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "22/22 - 0s - loss: 0.0756 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.7551 - val_sparse_categorical_accuracy: 0.6857 - 222ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "22/22 - 0s - loss: 0.0952 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.9878 - val_sparse_categorical_accuracy: 0.5943 - 229ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "22/22 - 0s - loss: 0.0921 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.7029 - 221ms/epoch - 10ms/step\n",
      "Epoch 67/100\n",
      "22/22 - 0s - loss: 0.0637 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6971 - 224ms/epoch - 10ms/step\n",
      "Epoch 68/100\n",
      "22/22 - 0s - loss: 0.0612 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.6800 - 225ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "22/22 - 0s - loss: 0.0580 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6624 - val_sparse_categorical_accuracy: 0.6914 - 227ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "22/22 - 0s - loss: 0.0609 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.7192 - val_sparse_categorical_accuracy: 0.6629 - 239ms/epoch - 11ms/step\n",
      "Epoch 71/100\n",
      "22/22 - 0s - loss: 0.0592 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6800 - 245ms/epoch - 11ms/step\n",
      "Epoch 72/100\n",
      "22/22 - 0s - loss: 0.0533 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.7512 - val_sparse_categorical_accuracy: 0.6400 - 244ms/epoch - 11ms/step\n",
      "Epoch 73/100\n",
      "22/22 - 0s - loss: 0.0546 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6914 - 243ms/epoch - 11ms/step\n",
      "Epoch 74/100\n",
      "22/22 - 0s - loss: 0.0467 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6847 - val_sparse_categorical_accuracy: 0.6914 - 232ms/epoch - 11ms/step\n",
      "Epoch 75/100\n",
      "22/22 - 0s - loss: 0.0469 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.6857 - 232ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "22/22 - 0s - loss: 0.0462 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6857 - 230ms/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "22/22 - 0s - loss: 0.0429 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6823 - val_sparse_categorical_accuracy: 0.6857 - 225ms/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "22/22 - 0s - loss: 0.0428 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.6914 - 242ms/epoch - 11ms/step\n",
      "Epoch 79/100\n",
      "22/22 - 0s - loss: 0.0420 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.6857 - 241ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "22/22 - 0s - loss: 0.0399 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7164 - val_sparse_categorical_accuracy: 0.6686 - 236ms/epoch - 11ms/step\n",
      "Epoch 81/100\n",
      "22/22 - 0s - loss: 0.0384 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6800 - 234ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "22/22 - 0s - loss: 0.0395 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.6914 - 298ms/epoch - 14ms/step\n",
      "Epoch 83/100\n",
      "22/22 - 0s - loss: 0.0358 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7198 - val_sparse_categorical_accuracy: 0.6686 - 249ms/epoch - 11ms/step\n",
      "Epoch 84/100\n",
      "22/22 - 0s - loss: 0.0390 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.6800 - 232ms/epoch - 11ms/step\n",
      "Epoch 85/100\n",
      "22/22 - 0s - loss: 0.0352 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.6971 - 223ms/epoch - 10ms/step\n",
      "Epoch 86/100\n",
      "22/22 - 0s - loss: 0.0328 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7139 - val_sparse_categorical_accuracy: 0.6743 - 233ms/epoch - 11ms/step\n",
      "Epoch 87/100\n",
      "22/22 - 0s - loss: 0.0315 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.6857 - 236ms/epoch - 11ms/step\n",
      "Epoch 88/100\n",
      "22/22 - 0s - loss: 0.0323 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7048 - val_sparse_categorical_accuracy: 0.6857 - 249ms/epoch - 11ms/step\n",
      "Epoch 89/100\n",
      "22/22 - 0s - loss: 0.0304 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.6800 - 240ms/epoch - 11ms/step\n",
      "Epoch 90/100\n",
      "22/22 - 0s - loss: 0.0290 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7109 - val_sparse_categorical_accuracy: 0.6857 - 266ms/epoch - 12ms/step\n",
      "Epoch 91/100\n",
      "22/22 - 0s - loss: 0.0291 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7164 - val_sparse_categorical_accuracy: 0.6857 - 245ms/epoch - 11ms/step\n",
      "Epoch 92/100\n",
      "22/22 - 0s - loss: 0.0279 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7137 - val_sparse_categorical_accuracy: 0.6800 - 249ms/epoch - 11ms/step\n",
      "Epoch 93/100\n",
      "22/22 - 0s - loss: 0.0270 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7154 - val_sparse_categorical_accuracy: 0.6743 - 244ms/epoch - 11ms/step\n",
      "Epoch 94/100\n",
      "22/22 - 0s - loss: 0.0263 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7176 - val_sparse_categorical_accuracy: 0.6743 - 234ms/epoch - 11ms/step\n",
      "Epoch 95/100\n",
      "22/22 - 0s - loss: 0.0273 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7219 - val_sparse_categorical_accuracy: 0.6743 - 247ms/epoch - 11ms/step\n",
      "Epoch 96/100\n",
      "22/22 - 0s - loss: 0.0276 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7319 - val_sparse_categorical_accuracy: 0.6800 - 246ms/epoch - 11ms/step\n",
      "Epoch 97/100\n",
      "22/22 - 0s - loss: 0.0252 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7349 - val_sparse_categorical_accuracy: 0.6971 - 238ms/epoch - 11ms/step\n",
      "Epoch 98/100\n",
      "22/22 - 0s - loss: 0.0247 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7335 - val_sparse_categorical_accuracy: 0.6914 - 242ms/epoch - 11ms/step\n",
      "Epoch 99/100\n",
      "22/22 - 0s - loss: 0.0242 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7288 - val_sparse_categorical_accuracy: 0.6743 - 232ms/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "22/22 - 0s - loss: 0.0230 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7300 - val_sparse_categorical_accuracy: 0.6743 - 234ms/epoch - 11ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Iteration: 4\n",
      "5 2 696\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 77028)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 77028)        0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 4)            308116      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 4)           8           ['dense_24[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 4)            20          ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 4)            0           ['dense_25[0][0]',               \n",
      "                                                                  'dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 4)           8           ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 4)            20          ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 4)            0           ['dense_26[0][0]',               \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 4)           8           ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 4)            20          ['layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 4)            0           ['dense_27[0][0]',               \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 4)           8           ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 4)            20          ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 4)            0           ['dense_28[0][0]',               \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 2)            10          ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 308,238\n",
      "Trainable params: 308,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "22/22 - 2s - loss: 0.8494 - sparse_categorical_accuracy: 0.5043 - val_loss: 0.8832 - val_sparse_categorical_accuracy: 0.4400 - 2s/epoch - 93ms/step\n",
      "Epoch 2/100\n",
      "22/22 - 0s - loss: 0.6738 - sparse_categorical_accuracy: 0.5934 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.5314 - 234ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "22/22 - 0s - loss: 0.6897 - sparse_categorical_accuracy: 0.5819 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.5257 - 252ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "22/22 - 0s - loss: 0.6485 - sparse_categorical_accuracy: 0.6351 - val_loss: 0.7346 - val_sparse_categorical_accuracy: 0.5600 - 234ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "22/22 - 0s - loss: 0.6361 - sparse_categorical_accuracy: 0.6322 - val_loss: 0.6830 - val_sparse_categorical_accuracy: 0.5486 - 255ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "22/22 - 0s - loss: 0.5956 - sparse_categorical_accuracy: 0.7241 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.5486 - 237ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "22/22 - 0s - loss: 0.5686 - sparse_categorical_accuracy: 0.7414 - val_loss: 0.7214 - val_sparse_categorical_accuracy: 0.5371 - 234ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "22/22 - 0s - loss: 0.5411 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.6680 - val_sparse_categorical_accuracy: 0.6229 - 287ms/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "22/22 - 0s - loss: 0.5385 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6662 - val_sparse_categorical_accuracy: 0.6171 - 243ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "22/22 - 0s - loss: 0.5410 - sparse_categorical_accuracy: 0.7557 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.5943 - 242ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "22/22 - 0s - loss: 0.5110 - sparse_categorical_accuracy: 0.7601 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.5714 - 289ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "22/22 - 0s - loss: 0.4872 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.5543 - 300ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "22/22 - 0s - loss: 0.4958 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.6607 - val_sparse_categorical_accuracy: 0.6171 - 297ms/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "22/22 - 0s - loss: 0.5036 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.5943 - 290ms/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "22/22 - 0s - loss: 0.4692 - sparse_categorical_accuracy: 0.8276 - val_loss: 0.6601 - val_sparse_categorical_accuracy: 0.6343 - 236ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "22/22 - 0s - loss: 0.4520 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.5943 - 242ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "22/22 - 0s - loss: 0.4218 - sparse_categorical_accuracy: 0.8477 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.5943 - 235ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "22/22 - 0s - loss: 0.4186 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.6000 - 236ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "22/22 - 0s - loss: 0.4000 - sparse_categorical_accuracy: 0.8793 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.5943 - 251ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "22/22 - 0s - loss: 0.3931 - sparse_categorical_accuracy: 0.8851 - val_loss: 0.7064 - val_sparse_categorical_accuracy: 0.6057 - 251ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "22/22 - 0s - loss: 0.3897 - sparse_categorical_accuracy: 0.8664 - val_loss: 0.7225 - val_sparse_categorical_accuracy: 0.5657 - 254ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "22/22 - 0s - loss: 0.3696 - sparse_categorical_accuracy: 0.8865 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.5943 - 258ms/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "22/22 - 0s - loss: 0.3814 - sparse_categorical_accuracy: 0.8664 - val_loss: 0.7680 - val_sparse_categorical_accuracy: 0.5886 - 249ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "22/22 - 0s - loss: 0.3914 - sparse_categorical_accuracy: 0.8520 - val_loss: 0.7313 - val_sparse_categorical_accuracy: 0.6114 - 242ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "22/22 - 0s - loss: 0.3571 - sparse_categorical_accuracy: 0.8721 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.5771 - 227ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "22/22 - 0s - loss: 0.3445 - sparse_categorical_accuracy: 0.8922 - val_loss: 0.6624 - val_sparse_categorical_accuracy: 0.6286 - 224ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "22/22 - 0s - loss: 0.4031 - sparse_categorical_accuracy: 0.8190 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.5886 - 235ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "22/22 - 0s - loss: 0.3228 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.6696 - val_sparse_categorical_accuracy: 0.6457 - 244ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "22/22 - 0s - loss: 0.3788 - sparse_categorical_accuracy: 0.8477 - val_loss: 0.6979 - val_sparse_categorical_accuracy: 0.6171 - 236ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "22/22 - 0s - loss: 0.3582 - sparse_categorical_accuracy: 0.8678 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.6229 - 279ms/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "22/22 - 0s - loss: 0.3459 - sparse_categorical_accuracy: 0.8707 - val_loss: 0.8225 - val_sparse_categorical_accuracy: 0.5829 - 259ms/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "22/22 - 0s - loss: 0.3183 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.6663 - val_sparse_categorical_accuracy: 0.6057 - 237ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "22/22 - 0s - loss: 0.3012 - sparse_categorical_accuracy: 0.9037 - val_loss: 0.7512 - val_sparse_categorical_accuracy: 0.5886 - 234ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "22/22 - 0s - loss: 0.3115 - sparse_categorical_accuracy: 0.9037 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.6000 - 226ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "22/22 - 0s - loss: 0.2638 - sparse_categorical_accuracy: 0.9282 - val_loss: 0.7747 - val_sparse_categorical_accuracy: 0.5886 - 230ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "22/22 - 0s - loss: 0.3583 - sparse_categorical_accuracy: 0.8707 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.6000 - 253ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "22/22 - 0s - loss: 0.2780 - sparse_categorical_accuracy: 0.9152 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6057 - 225ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "22/22 - 0s - loss: 0.2328 - sparse_categorical_accuracy: 0.9440 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.5943 - 234ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "22/22 - 0s - loss: 0.2767 - sparse_categorical_accuracy: 0.9124 - val_loss: 1.4169 - val_sparse_categorical_accuracy: 0.5429 - 239ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "22/22 - 0s - loss: 0.2839 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.7719 - val_sparse_categorical_accuracy: 0.6000 - 255ms/epoch - 12ms/step\n",
      "Epoch 41/100\n",
      "22/22 - 0s - loss: 0.2350 - sparse_categorical_accuracy: 0.9397 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6114 - 252ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "22/22 - 0s - loss: 0.2993 - sparse_categorical_accuracy: 0.8937 - val_loss: 0.7668 - val_sparse_categorical_accuracy: 0.6057 - 242ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "22/22 - 0s - loss: 0.1966 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.8491 - val_sparse_categorical_accuracy: 0.5714 - 234ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "22/22 - 0s - loss: 0.2332 - sparse_categorical_accuracy: 0.9239 - val_loss: 0.7453 - val_sparse_categorical_accuracy: 0.6343 - 253ms/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "22/22 - 0s - loss: 0.2825 - sparse_categorical_accuracy: 0.9066 - val_loss: 0.7175 - val_sparse_categorical_accuracy: 0.6171 - 258ms/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "22/22 - 0s - loss: 0.1916 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.7115 - val_sparse_categorical_accuracy: 0.6229 - 246ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "22/22 - 0s - loss: 0.1750 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.7054 - val_sparse_categorical_accuracy: 0.6114 - 264ms/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "22/22 - 0s - loss: 0.1734 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.7140 - val_sparse_categorical_accuracy: 0.6057 - 253ms/epoch - 12ms/step\n",
      "Epoch 49/100\n",
      "22/22 - 0s - loss: 0.2023 - sparse_categorical_accuracy: 0.9468 - val_loss: 0.8025 - val_sparse_categorical_accuracy: 0.5829 - 245ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "22/22 - 0s - loss: 0.1772 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.7321 - val_sparse_categorical_accuracy: 0.6229 - 260ms/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "22/22 - 0s - loss: 0.1840 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.7754 - val_sparse_categorical_accuracy: 0.6229 - 244ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "22/22 - 0s - loss: 0.1457 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.8331 - val_sparse_categorical_accuracy: 0.6000 - 245ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "22/22 - 0s - loss: 0.1331 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.7382 - val_sparse_categorical_accuracy: 0.6057 - 239ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "22/22 - 0s - loss: 0.1412 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.7554 - val_sparse_categorical_accuracy: 0.5886 - 238ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "22/22 - 0s - loss: 0.2496 - sparse_categorical_accuracy: 0.9339 - val_loss: 0.8581 - val_sparse_categorical_accuracy: 0.6000 - 255ms/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "22/22 - 0s - loss: 0.1434 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.7814 - val_sparse_categorical_accuracy: 0.5943 - 239ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "22/22 - 0s - loss: 0.2206 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.7578 - val_sparse_categorical_accuracy: 0.6286 - 257ms/epoch - 12ms/step\n",
      "Epoch 58/100\n",
      "22/22 - 0s - loss: 0.1464 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.7931 - val_sparse_categorical_accuracy: 0.6114 - 262ms/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "22/22 - 0s - loss: 0.1255 - sparse_categorical_accuracy: 0.9741 - val_loss: 1.3414 - val_sparse_categorical_accuracy: 0.5657 - 234ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "22/22 - 0s - loss: 0.1435 - sparse_categorical_accuracy: 0.9655 - val_loss: 0.8047 - val_sparse_categorical_accuracy: 0.6229 - 249ms/epoch - 11ms/step\n",
      "Epoch 61/100\n",
      "22/22 - 0s - loss: 0.1205 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.9086 - val_sparse_categorical_accuracy: 0.5886 - 241ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "22/22 - 0s - loss: 0.1952 - sparse_categorical_accuracy: 0.9310 - val_loss: 0.8112 - val_sparse_categorical_accuracy: 0.6000 - 234ms/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "22/22 - 0s - loss: 0.1520 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.7797 - val_sparse_categorical_accuracy: 0.6286 - 244ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "22/22 - 0s - loss: 0.1287 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.7950 - val_sparse_categorical_accuracy: 0.6343 - 230ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "22/22 - 0s - loss: 0.0882 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.9728 - val_sparse_categorical_accuracy: 0.5829 - 243ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "22/22 - 0s - loss: 0.0743 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.8127 - val_sparse_categorical_accuracy: 0.6000 - 235ms/epoch - 11ms/step\n",
      "Epoch 67/100\n",
      "22/22 - 0s - loss: 0.1246 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.8689 - val_sparse_categorical_accuracy: 0.6114 - 242ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "22/22 - 0s - loss: 0.1007 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.9321 - val_sparse_categorical_accuracy: 0.5943 - 241ms/epoch - 11ms/step\n",
      "Epoch 69/100\n",
      "22/22 - 0s - loss: 0.0770 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.9174 - val_sparse_categorical_accuracy: 0.6171 - 256ms/epoch - 12ms/step\n",
      "Epoch 70/100\n",
      "22/22 - 0s - loss: 0.1338 - sparse_categorical_accuracy: 0.9612 - val_loss: 1.1357 - val_sparse_categorical_accuracy: 0.5771 - 255ms/epoch - 12ms/step\n",
      "Epoch 71/100\n",
      "22/22 - 0s - loss: 0.0941 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.8125 - val_sparse_categorical_accuracy: 0.6114 - 241ms/epoch - 11ms/step\n",
      "Epoch 72/100\n",
      "22/22 - 0s - loss: 0.0754 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.8270 - val_sparse_categorical_accuracy: 0.6171 - 247ms/epoch - 11ms/step\n",
      "Epoch 73/100\n",
      "22/22 - 0s - loss: 0.0600 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.8336 - val_sparse_categorical_accuracy: 0.6171 - 250ms/epoch - 11ms/step\n",
      "Epoch 74/100\n",
      "22/22 - 0s - loss: 0.1327 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.8968 - val_sparse_categorical_accuracy: 0.6400 - 229ms/epoch - 10ms/step\n",
      "Epoch 75/100\n",
      "22/22 - 0s - loss: 0.0622 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8842 - val_sparse_categorical_accuracy: 0.6229 - 267ms/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "22/22 - 0s - loss: 0.0512 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8478 - val_sparse_categorical_accuracy: 0.6286 - 246ms/epoch - 11ms/step\n",
      "Epoch 77/100\n",
      "22/22 - 0s - loss: 0.0438 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8704 - val_sparse_categorical_accuracy: 0.6229 - 229ms/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "22/22 - 0s - loss: 0.2296 - sparse_categorical_accuracy: 0.9109 - val_loss: 0.8034 - val_sparse_categorical_accuracy: 0.6343 - 261ms/epoch - 12ms/step\n",
      "Epoch 79/100\n",
      "22/22 - 0s - loss: 0.0804 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7850 - val_sparse_categorical_accuracy: 0.6057 - 231ms/epoch - 10ms/step\n",
      "Epoch 80/100\n",
      "22/22 - 0s - loss: 0.0799 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8022 - val_sparse_categorical_accuracy: 0.6400 - 252ms/epoch - 11ms/step\n",
      "Epoch 81/100\n",
      "22/22 - 0s - loss: 0.0737 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8141 - val_sparse_categorical_accuracy: 0.6343 - 235ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "22/22 - 0s - loss: 0.0858 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.8077 - val_sparse_categorical_accuracy: 0.6057 - 234ms/epoch - 11ms/step\n",
      "Epoch 83/100\n",
      "22/22 - 0s - loss: 0.0738 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.8148 - val_sparse_categorical_accuracy: 0.6229 - 238ms/epoch - 11ms/step\n",
      "Epoch 84/100\n",
      "22/22 - 0s - loss: 0.0649 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8121 - val_sparse_categorical_accuracy: 0.6286 - 232ms/epoch - 11ms/step\n",
      "Epoch 85/100\n",
      "22/22 - 0s - loss: 0.0705 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.8090 - val_sparse_categorical_accuracy: 0.6114 - 229ms/epoch - 10ms/step\n",
      "Epoch 86/100\n",
      "22/22 - 0s - loss: 0.0582 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8136 - val_sparse_categorical_accuracy: 0.6114 - 222ms/epoch - 10ms/step\n",
      "Epoch 87/100\n",
      "22/22 - 0s - loss: 0.0566 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8637 - val_sparse_categorical_accuracy: 0.6286 - 239ms/epoch - 11ms/step\n",
      "Epoch 88/100\n",
      "22/22 - 0s - loss: 0.0561 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8378 - val_sparse_categorical_accuracy: 0.6229 - 276ms/epoch - 13ms/step\n",
      "Epoch 89/100\n",
      "22/22 - 0s - loss: 0.0470 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9007 - val_sparse_categorical_accuracy: 0.6286 - 266ms/epoch - 12ms/step\n",
      "Epoch 90/100\n",
      "22/22 - 0s - loss: 0.0604 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8603 - val_sparse_categorical_accuracy: 0.6286 - 301ms/epoch - 14ms/step\n",
      "Epoch 91/100\n",
      "22/22 - 0s - loss: 0.0510 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8279 - val_sparse_categorical_accuracy: 0.6286 - 249ms/epoch - 11ms/step\n",
      "Epoch 92/100\n",
      "22/22 - 0s - loss: 0.0476 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8281 - val_sparse_categorical_accuracy: 0.6343 - 240ms/epoch - 11ms/step\n",
      "Epoch 93/100\n",
      "22/22 - 0s - loss: 0.0470 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8649 - val_sparse_categorical_accuracy: 0.6171 - 227ms/epoch - 10ms/step\n",
      "Epoch 94/100\n",
      "22/22 - 0s - loss: 0.0473 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8717 - val_sparse_categorical_accuracy: 0.6400 - 238ms/epoch - 11ms/step\n",
      "Epoch 95/100\n",
      "22/22 - 0s - loss: 0.0419 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8411 - val_sparse_categorical_accuracy: 0.6400 - 250ms/epoch - 11ms/step\n",
      "Epoch 96/100\n",
      "22/22 - 0s - loss: 0.0386 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8479 - val_sparse_categorical_accuracy: 0.6057 - 234ms/epoch - 11ms/step\n",
      "Epoch 97/100\n",
      "22/22 - 0s - loss: 0.0419 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8846 - val_sparse_categorical_accuracy: 0.6000 - 233ms/epoch - 11ms/step\n",
      "Epoch 98/100\n",
      "22/22 - 0s - loss: 0.0392 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8524 - val_sparse_categorical_accuracy: 0.6057 - 265ms/epoch - 12ms/step\n",
      "Epoch 99/100\n",
      "22/22 - 0s - loss: 0.0351 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8635 - val_sparse_categorical_accuracy: 0.6057 - 247ms/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "22/22 - 0s - loss: 0.0358 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8612 - val_sparse_categorical_accuracy: 0.6114 - 243ms/epoch - 11ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 175\n",
    "labels_accuracy = 0.0\n",
    "labels_accuracy_storage = np.empty(10,dtype=float)\n",
    "results = np.empty((10,4), dtype=float)\n",
    "\n",
    "#10 times cross validation\n",
    "for x in range(5):\n",
    "    print(\"Iteration:\", x)\n",
    "    stratifiedRandomSampling()\n",
    "    model = modelConstructor(4,4)\n",
    "    history = model.fit(x_data_sampled_train, y_data_sampled_train,\n",
    "                epochs=100,\n",
    "                verbose=2,\n",
    "                batch_size=32,\n",
    "                validation_data=(x_data_sampled_val,y_data_sampled_val))\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    accuracy = history.history['sparse_categorical_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_accuracy = history.history['val_sparse_categorical_accuracy']\n",
    "    \n",
    "    #get final results using last indexes\n",
    "    results[x][0] = loss[-1]\n",
    "    results[x][1] = accuracy[-1]\n",
    "    results[x][2] = val_loss[-1]\n",
    "    results[x][3] = val_accuracy[-1]\n",
    "    \n",
    "    output = model.predict(x_data_sampled_val[0:])\n",
    "    np.argmax(output,axis=1)\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for b in range(175):\n",
    "        temp1 = output[b][0]\n",
    "        temp2 = y_data_sampled_val[b]\n",
    "        if temp1 == temp2:\n",
    "            correct += 1\n",
    "    \n",
    "    labels_accuracy = correct/total\n",
    "    labels_accuracy_storage[x] = labels_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7588527b-c545-4f68-9f09-3e4dbb241b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss Average: 0.03578\n",
      "Training Accuracy Average: 100.00%\n",
      "Validation Loss Average: 0.86116\n",
      "Validation Accuracy Average: 61.14286%\n",
      "Label Accuracy Average: 0.00%\n"
     ]
    }
   ],
   "source": [
    "loss_avg = 0.0\n",
    "accuracy_avg = 0.0\n",
    "val_loss_avg = 0.0\n",
    "val_accuracy_avg = 0.0\n",
    "labels_accuracy_avg = 0.0\n",
    "\n",
    "for a in range(10):\n",
    "    loss_avg += results[x][0]\n",
    "for a in range(10):\n",
    "    accuracy_avg += results[x][1]\n",
    "for a in range(10):\n",
    "    val_loss_avg += results[x][2]\n",
    "for a in range(10):\n",
    "    val_accuracy_avg += results[x][3]\n",
    "    \n",
    "loss_avg = loss_avg / 10\n",
    "accuracy_avg = accuracy_avg / 10 * 100\n",
    "val_loss_avg = val_loss_avg / 10\n",
    "val_accuracy_avg = val_accuracy_avg / 10 * 100\n",
    "\n",
    "for a in range(10):\n",
    "    labels_accuracy_avg += labels_accuracy_storage[a]\n",
    "    \n",
    "labels_accuracy_avg = labels_accuracy_avg / 10 * 100\n",
    "\n",
    "print(\"Training Loss Average: {a:1.5f}\".format(a = loss_avg))\n",
    "print(\"Training Accuracy Average: {a:1.2f}%\".format(a = accuracy_avg))\n",
    "print(\"Validation Loss Average: {a:1.5f}\".format(a = val_loss_avg))\n",
    "print(\"Validation Accuracy Average: {a:1.5f}%\".format(a = val_accuracy_avg))\n",
    "print(\"Label Accuracy Average: {a:1.2f}%\".format(a = labels_accuracy_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cffa6-347b-48bf-93b8-23b1cf4abcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
